Work notes


+44 7794 638148



rgandrews@hotmail.co.ul

booking ref:
Mine: 
rh



300 20.450871467590332
[0.04693294 0.0468061  0.06249738 0.09379482 0.06244946 0.07810426
 0.06249213 0.09373927 0.07808733 0.09376812 0.06250548 0.07812047
 0.06249475 0.06250381 0.07811427 0.07818341 0.07809639 0.07813406
 0.07812023 0.07810712 0.0937407  0.09373975 0.09373188 0.09373832
 0.09374595 0.09374499 0.09374309 0.10936308 0.10936332 0.09374142
 0.10936093 0.10936093 0.12498856 0.10935998 0.12498283 0.12499309
 0.14061069 0.12503982 0.14060974 0.14062214 0.15623283 0.15618515
 0.15623236 0.15623379 0.15623379 0.1562345  0.17185879 0.1718576
 0.18752646 0.23440289 0.17185068 0.18748617 0.18749547 0.18748045
 0.20309544 0.20310998 0.20309162 0.20310235 0.21871758 0.21920896
 0.24992728 0.21872759 0.26554346 0.28129148 0.26554871 0.28126836
 0.31234908 0.24997544 0.31246591 0.29684329 0.3124361  0.35940218
 0.29688072 0.32807827 0.54753733 0.57807231 0.5312531  0.43745255
 0.45308495 0.37490344 0.4061482  0.37496424 0.3749609  0.43745375
 0.42182183 0.37495899 0.40614605 0.3749063  0.37495923 0.40620565
 0.40620375 0.42182899 0.37500429 0.40620732 0.40674281 0.40620279
 0.45307612 0.45308018 0.42182684 0.45307636 0.45309067 0.46874571
 0.49994731 0.49994707 0.51557016 0.53113413 0.46869612 0.43750191
 0.62486291 1.21861959 0.99989009 0.89052916 0.92177582 0.89052916
 0.81247592 0.74991703 1.01527548 0.72174358 0.68772602 0.99993944
 1.04675484 0.95302296 0.84366059 0.82803321 1.03031731 0.77119184
 0.89575791 0.87549305 0.7656374  0.77961683 0.75199962 0.95996809
 0.78399825 0.96805239 0.79195452 1.09883118 0.89592028 0.79999781
 0.73604703 0.7680006  0.91554928 1.09374213 1.15612674 0.85928202
 1.21861601 1.53115082 1.39750218 1.31236053 1.15612125 1.124964
 0.85922432 1.04675531 1.43734789 1.35922885 1.23424149 1.26549625
 1.35951257 1.43734646 1.43734717 0.89051867 0.98421597 0.96858311
 0.96864414 1.04676652 1.01400137 1.10934091 0.99996328 1.07794881
 1.48317957 1.68731833 1.54675937 1.42218781 1.28105712 1.67169809
 1.34361053 1.42172503 1.12481594 1.390872   1.54669881 1.35923171
 1.42369246 1.15606213 1.07800817 1.62426996 1.43999791 1.29606867
 1.29600239 1.28840756 1.29667783 1.18036127 1.15611792 1.374856
 1.15618277 1.73432875 2.34157801 2.18773723 1.8591826  1.8469348
 1.74981093 1.9997859  1.87587357 2.01540828 2.37516117 2.12477517
 1.67213941 1.67167401 1.34354687 1.3749001  1.09357619 1.32855701
 1.218606   1.62482476 1.59402943 1.17181468 1.14045691 1.14050126
 1.15612888 1.12488079 1.10925794 1.21911335 2.07211041 2.42161775
 1.89042091 1.70294261 1.98417902 2.10914946 2.53097963 3.01535797
 2.04673767 1.4686017  1.58161449 1.51547527 1.71496606 1.8698411
 2.68725967 2.40599704 2.09989524 2.18627381 2.15602636 2.29663372
 2.54665089 2.17165589 1.99985576 1.96853518 2.10915136 2.32787538
 2.60908699 2.35912085 2.26538777 2.39037466 2.53098631 2.78090024
 2.02036715 2.03102922 1.89041257 2.00987434 2.24976254 2.59346509
 2.34350157 2.10916424 2.31225467 2.2498064  2.40594125 2.39042187
 2.06232357 2.12472248 2.20289159 1.8904264  1.94170141 3.10937953
 2.53098631 2.48467898 2.45286345 2.62471604 2.65597057 2.1872704
 2.18732762 2.26597357 2.28102422 2.92162299 2.14038706 1.92167449
 1.84354997 1.89023066 1.81235147 1.90600181 2.2029376  1.87477541
 1.96857047 1.90657949 1.95297909 1.87484789 2.48408413 2.21850657
 1.95291662 1.90598249 2.01543045 1.89037752 2.0309875  2.1247592 ]
Took 337.88607144355774 seconds to build 300 models

Process finished with exit code 0


Can i read the object model from the cache???

check if model cache name is md5


what am i trying to do?
    - load state from LLJit

Strategy?
    - On save state, save a copy of the module. Do this without converting to 
      string if possible.
        - also need to save the md5 to load the object, which is named md5. 

    - So go into the save state fn, get the current model object from cache
      and save it to binary, like everything else. You miht need to change them from ref to pointer (you did this last time).
    - Then you need to load from binary, ensuring the calls to load from 
      stream are in the correct order.  
    - Once you have a MemoryBuffer you should be able to add this as a module/object to the jit. 
    - See if you can get this working for MCJit before LLJit, since it'd be nice to use the same mechanism for both. 

caching
    - Model resources are already chached
    - ModelResources already has a jit member variable, which is (should) also be cached. 
    - Therefore, the ModelResources cache should *use* the llvm object cache for loading the module. 

Once this is done, think about removing the ModelGeneratorContext and only using Jit. 

Convert cached model to string. 

Need to test saving and loading in different roadrunner sessions. 

If suitcase hasn't arrived by Monday, call Kelly from sherpr.

        if (modelResources->moduleStr.empty()){
            std::unique_ptr<llvm::MemoryBuffer> memBuf = modelGeneratorContext
                    ->getJitNonOwning()->getCompiledModelFromCache(modelResources->sbmlMD5);
            rrLogCriticalCiaran << "no find the memory buffer";
            MemoryBufferRef memBufRef = memBuf->getMemBufferRef();
            modelResources->moduleStr = memBufRef.getBuffer().str();
        }

        if (rc->moduleStr.empty()){
            std::unique_ptr<llvm::MemoryBuffer> memBuf = modelGeneratorContext
                    ->getJitNonOwning()->getCompiledModelFromCache(rc->sbmlMD5);
            rrLogCriticalCiaran << "no find the memory buffer";
            MemoryBufferRef memBufRef = memBuf->getMemBufferRef();
            rc->moduleStr = memBufRef.getBuffer().str();
        }


After we have used the lookup function address, we shoud be able to use the cache



Where is the call to put a compiled object into the object cache? 



/// This is the base ObjectCache type which can be provided to an
/// ExecutionEngine for the purpose of avoiding compilation for Modules that
/// have already been compiled and an object file is available.


--> This means that we should be able to get the MCJit to use the object cache as well. 


void MCJIT::setObjectCache(ObjectCache* NewCache) {
  std::lock_guard<sys::Mutex> locked(lock);
  ObjCache = NewCache;
}


LLVM has a MCJit which is derived from the execution engine. 

Does the compile only happen once we start looking for symbols?



0x222f2420710

16/11/2021
----------------
LLJit cached the model and I'm pretty sure I've seen that it is possible to also cache the MCJit. 
    Wait no, MCJit is its own class in llvm. So you should see if you use aggregation rather than piecing it all together yourself???\

Currently the MCJit and LLJit use different mechanisms for storing the compiled module as binary. MCJit uses a stream which is a member variable of the Jit whilst LLJit uses a cache that is a LLVM construct to store and retrieve binaries. 

In order for these to use the same mechanism (the cache) I need, MCJit to actually use the MCJit from llvm, at the moment it does not. 

Right, now what? 

Things to do: 
    - Python tests for lucian
    - Write performance test suites. 
    - Add some options for LLJit thread and optimization level to expose to user. 
    - Custom optimization? Third jit with new optimizations? 
    - Think about your optimizations optimization program, could be interesting. 

GOEDBEZORGD15

Some notes
-----------
- The MCJit that is released in roadrunner v2.1.3 is not the same as the 
  MCJit shown here.  
- Simulation time


I can't create llvm-13 binary releases. 
I can't access roadrunner azure.



Clion - use clang to build roadrunner. 
Can I use the profiling tools?






Could i resolve this with caching?

What is the problem? 
---------------------
MCJit writes binary object file to an in memory stream. This stream is converted into an object file before adding it to the jit. When saving state, we read directly from the stream, convert it to a string and save it with everything else. 

However, in the save_State tests, we actually try to save and load from a COPY of a roadrunner model so the lifetime of the stream containing the binary has ended(?).
    Check this by looking at the address of the stream. 




POints for meeting 
-------------------
- I think the key thing for this meeting is to give you an update on where I'm at with llvm-13 and Jit world and to discuss how to build an effective measure of roadrunner's performance. 
- I intend to use this performance suite with profilers to locate bottlenecks and hopefully speed the roadrunner build. 
- I also want to build 2 more Jit compiler options
    - Lazy jit compiler - compile functions on demand. 
    - Custom transform layer. The issue with LLJit is that its "out of the box", meaning general and non-specific. I want to run each of th


- load/save state bug when saving a copy of a roadrunner model. Will fix this tomorrow


Scalar.h

Large models, lots of reactions, large rate laws. 10-20 reactions. 

teutils -- random network generator. 

Check




ModelResources has a jit member variable. It is initially empty but in the course of creating the model (and ModelResources) it is transferred from ModelGenerator to ModelResources. It looks like this breaks down when copying a roadrunner model. 

LLVMExecutableModel has a ModelResources. 
When copying a RoadRunner model, I assume the ExecutableModel is also copied. So do we copy the Jit?

Custom copy constructors for Jit etc.


Either need to populate the postOptStream (Which needs renaming) or see if the moduleStr is populated and try to use that first. 

llvm::raw_svector_ostream compiledModuleStream


- takes a module buffer

llvm::SmallVector<char, 10> moduleBuffer;
std::make_unique<llvm::raw_svector_ostream>(moduleBuffer);


Can I use the model cache for MCJit? 

Serialize the stream, not the string? 

Sometimes copying a roadrunner isntance results in the SmallVEctory memory buffer / manager part of the raw_svector_ostream is nullptr. 

And where is the file were trying to load anyway???


24/11/2021
----------
What to include in the performance test suite? 
    - Use RNG to generate small, medium and large MM kinetic models. 10, 50 and 100 reactions with complex chemical kinetics. 
        - Check for simulation time. Run the three models many times. 
        - Check for build time. Build many times. 
    - 


    Simulate until steady state



def timeOfSteadyState(sbmlFile, tol=1e-3, verbose=False):
    """figure out at which time a model reaches steady state

    Starts with a high tolerance and iteratively gets more accurate time
    of steady state.

    Assumes model has a steady state.

    Args:
        sbmlFile: input model
        tol: how close to actual steady state do values need to
             be before time accepted.
    """
    rr = RoadRunner(sbmlFile)
    initFloatingVals = rr.getFloatingSpeciesAmountsNamedArray()
    print(initFloatingVals)
    rr.setSteadyStateSolver("newton")
    rr.steadyState()
    ssValues = rr.getFloatingSpeciesAmountsNamedArray()
    sumOfSSValues = ssValues.sum()
    rr.resetAll()

    # variable to store current floating species
    currentValues = None

    cvode = roadrunner.CVODEIntegrator(rr.getModel())

    # if tol > 1:
    #     raise ValueError("please use a tol of 1 or lower.")

    # desired accuracy
    targetTol = tol

    # starting accuracy
    tol = initFloatingVals.sum() / 10

    # starting sumOfErrors
    sumOfErrors = 1e8

    # initial step size. Gets smaller with smaller tolerances
    stepSize = 1

    currentTime = stepSize

    while not targetTol >= tol: # tol approaches targetTol with iterations
        rr.reset()
        if verbose:
            print("ssValues:\n", ssValues)
            print("sumOfSSValues:", sumOfSSValues)
            print("currentValues:\n", currentValues)
            print(f"tol: {tol}")
            print(f"targetTol: {targetTol}")
            print(f"stepSize: {stepSize}")
            print(f"not {targetTol} >= {tol}: { not targetTol >= tol}")

        while np.abs(sumOfErrors - sumOfSSValues) > tol:
            if verbose:
                print(f"\trunning {currentTime}")
            cvode.integrate(0, currentTime)
            currentValues = rr.getFloatingSpeciesAmountsNamedArray()
            sumCurrentValues = currentValues.sum()
            sumOfErrors = sumCurrentValues.sum()
            currentTime += stepSize
            if verbose:
                print(f"\tnp.abs({sumOfErrors} - {sumOfSSValues}) > {tol} : {np.abs(sumOfErrors - sumOfSSValues) > tol}")

        # reduce tolerance and step size by factor 10
        tol /= 10
        stepSize /= 10
    if verbose:
        print(f"computed steady state values: \n {ssValues}")
        print(f"time at steady state: {rr.getCurrentTime()}")
        print(f"floating species at time of steady state \n{currentValues}")
    return rr.getCurrentTime()


695E7E9AFC26



I've thought about putting roadrunner on vcpkg before, but it doesn't get used from C++ enough to warrent spending the time on it. 


When C++

setting_t.h
RegistrationFactory.h RegistrationFactory.cpp



Now I want to change just one function. I want the RoadRunnerMap.getKeys() currently gets converted into a tuple of strings. I want a dict_keys type. 

PhD Supervisor: Dr Daryl Shanley, Institute for Ageing and Health, Newcastle University, Biogerontology Building, 
Campus for Ageing and Vitality, Newcastle upon Tyne, NE4 5PL, Tel: +44 (0) 191 208 1105, daryl.shanley@ncl.ac.uk

3720 15th Ave NE, Seattle, WA 98105, United States Tel. +1 206-685-2000,
hsauro@uw.edu

I want to evaluate the quality of the existing code and determine for myself whether I think the software stack in use is appropriate for the requirements. I'm worried that I'll start the job and be locked in to using tools that have already been used, despite being inappropriate for the job. 


Honestly, I need C++ in my next job. I can't take a position that will take me away too far away from it. 

It take so much expertise to become competant C++ developer that now I have some I'm reluctant to just let it go so easily. 

Can I restrict a typemap to a specific function? 



Hi Ciaran,
 
Thank you very much for sending the payslips over to us, I have saved these into the personal tax folder to be included on your self assessment for 20/21 tax year.

Having looked at that income from the employment and the income from the company you still have £9,200 left of your basic rate tax band (taxed at 7.5%). Looking at your company profits, as of the end of the 20/21 tax year you had £7,200 in retained profit which you could potentially raise as a dividend. I would be happy to backdate this for you if you wish so we can include in the self assessment?

Please note an increase in the dividends will increase the student loan you will need to repay on the self assessment.


70079f75a631f0ac0f23a22277ed10b7

70079f75a631f0ac0f23a22277ed10b7


My github is https://github.com/CiaranWelsh. 
Please follow links from my CV for a more "guided" tour. 
All recent work (2 years) has been done on my work github. 
Relevant projects:
    - https://github.com/sys-bio/roadrunner
    - https://github.com/sys-bio/libOmexMeta


    std::vector<bool> inArray(text.size());
    for (int i=0; i<inArray.size(); i++) inArray[i] = false;
    for (int i=0; i<text.size() ; i++){
        for (int j=i+1; j<text.size(); j++){
            if (!barcodes_equal(barcodes[i], barcodes[j])){
                if (! inArray[i]){
                    ans.push_back(text[i]);
                    inArray[i] = true;
                }
                if (! inArray[j]){
                    ans.push_back(text[j]);
                    inArray[j] = true;
                }
            } else {
                if (!inArray[i]){
                ans.push_back(text[i]);
                inArray[i] = true;
                }
            }
        }
    }
   
    // remove duplicates
    auto barcodesItI = barcodes.begin();
    i = 0;
    auto barcodesItJ = barcodes.begin()+1;
    while (barcodesItI != barcodes.end()){
        if (!barcodes_equal(*barcodesItI, *barcodesItJ)){
            ans.push_back(text[i]);
            barcodesItI++
        }
    }



    for (int i=0; i<text.size() ; i++){
        for (int j=i+1; j<text.size(); j++){
            if (!barcodes_equal(barcodes[i], barcodes[j])){
                ans.push_back(text[i]);
                continue;
            } else {
                ans.push_back(text[i]);
                continue;
            }
        }
    }

        std::unique(barcodes.begin(), barcodes.end(), [](std::array<int, 128>& first, std::array<int, 128>& second){
        return barcodes_equal(first, second);
    });








Rhiannon        - done!
Colleen         - Huel. 30-40
Ritch           - Beer. Classic, dependible beer. 62

Mum             - Yellow rain coat 60? 
Anna            - afternoon tea together/ baking / Squid games / theatre / music / moutain warehouse



So where does registrars disappear???








songs
-------


- pink floyd
    - Money
    - Breathe
    - Hey you
- Beatles 

- Artic monkeys
    - Do i wanna know



Jan 2022 Challenges
---------------------
- vegetarian
- loose a reasonable amount of belly fat
- gain a reasonable amount of muscle
- Play 10 minutes of guitar or bass per day
- One exercise per day
- Huel?

2021-01-01 -- 2021-04-01
2021-04-02 -- 2021-07-05
2021-07-05 -- 2021-10-07
2021-10-07 -- 


Things I need to do
---------------------------
- document RoadRunnerMap
- Document new compiler and switching. 
- Ask Herbert about default Jit compiler. 
- Run performance tests again. 




wget https://sourceware.org/pub/valgrind/valgrind-3.18.1.tar.bz2 --no-check-certificate

tar -xvf valgrind-3.18.1.tar.bz2
cd valgrind-3.18.1/
mkdir build
cd build
../configure                                                
make -j 12
make install                                               



"C:\Program Files (x86)\Intel\oneAPI\vtune\latest\bin64\vtune" -collect hotspots -app-working-dir D:\roadrunner\roadrunner\cmake-build-debug\bin --app-working-dir=D:\roadrunner\roadrunner\cmake-build-debug\bin -- D:\roadrunner\roadrunner\cmake-build-debug\bin\RoadRunnerMapPerformanceTests.exe --OutputDirectory D:\roadrunner\Profiler\RoadRunnerProfiling




D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_4_BuildParallel\LLJit_100_4_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_5_BuildParallel\LLJit_100_5_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_6_BuildParallel\LLJit_100_6_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_7_BuildParallel\LLJit_100_7_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_8_BuildParallel\LLJit_100_8_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_9_BuildParallel\LLJit_100_9_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_10_BuildParallel\LLJit_100_10_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_11_BuildParallel\LLJit_100_11_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_12_BuildParallel\LLJit_100_12_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_13_BuildParallel\LLJit_100_13_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_14_BuildParallel\LLJit_100_14_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\LLJit_100_15_BuildParallel\LLJit_100_15_BuildParallel.vtunevtune

D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_4_BuildParallel\MCJit_100_1_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_4_BuildParallel\MCJit_100_2_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_4_BuildParallel\MCJit_100_3_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_4_BuildParallel\MCJit_100_4_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_5_BuildParallel\MCJit_100_5_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_6_BuildParallel\MCJit_100_6_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_7_BuildParallel\MCJit_100_7_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_8_BuildParallel\MCJit_100_8_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_9_BuildParallel\MCJit_100_9_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_10_BuildParallel\MCJit_100_10_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_11_BuildParallel\MCJit_100_11_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_12_BuildParallel\MCJit_100_12_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_13_BuildParallel\MCJit_100_13_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_14_BuildParallel\MCJit_100_14_BuildParallel.vtunevtune
D:\roadrunner\Profiler\RoadRunnerMapProfilingHotspots\MCJit_100_15_BuildParallel\MCJit_100_15_BuildParallel.vtunevtune



LLVMModelSymbols is a contender. 
- We have indices via the LLVMModelDataSymbols, which could be renamed to something more obvious. 
- So we need a vector somewhere which is of size num floating + num boundary species. Use the same indices to a bool vector. 


We have a ModelDataIRBuilder, which has a LLVMModelDataSymbols, which seems like a good candidate for storing hasOnlySubstanceUnits. 

LLVMModelDataSymbols has SpeciesReferenceInfo struct. I've added hasOnlySubstanceUnits field to it. This can be used in code gen conditionals. 


Why are we first creating a list and then a map? 

Try replacing std::map with std::unordered map. O(1) average access time. 


    std::unordered_map<std::string, libsbml::Species*> floatingSpeciesMap;
    std::unordered_map<std::string, libsbml::Species*> boundarySpeciesMap;




//            const Species* species = const_cast<Model*>(model)->getSpecies(rateRuleVariable);
            bool hasOnlySubstanceUnits;
            // search for boundary species, not floating as usually smaller.
            // uses std::map::find, O(log N).
            if (dataSymbols.isBoundarySpecies(rateRuleVariable)){
                const int& idx = dataSymbols.getBoundarySpeciesIndex(rateRuleVariable);
                hasOnlySubstanceUnits = dataSymbols.getBoundarySpeciesHasOnlySubstanceUnits()[idx];
            } else {
                const int& idx = dataSymbols.getFloatingSpeciesIndex(rateRuleVariable);
                hasOnlySubstanceUnits = dataSymbols.getFloatingSpeciesHasOnlySubstanceUnits()[idx];
            }






//            const Species* species = const_cast<Model*>(model)->getSpecies(rateRuleVariable);
            bool hasOnlySubstanceUnits;
            const libsbml::Compartment* speciesCompartment = nullptr;
            std::string speciesCompartmentName;
            // search for boundary species, not floating as usually smaller.
            // uses std::map::find, O(log N).
            if (dataSymbols.isBoundarySpecies(rateRuleVariable)){
                const int& idx = dataSymbols.getBoundarySpeciesIndex(rateRuleVariable);
                const_cast<Model*>(model)->getSpecies(idx);
                hasOnlySubstanceUnits = dataSymbols.getBoundarySpeciesHasOnlySubstanceUnits()[idx];
                const uint& compIdx = dataSymbols.getCompartmentIndexForBoundarySpecies(idx);
                speciesCompartment = model->getCompartment(compIdx);
            } else {
                const int& idx = dataSymbols.getFloatingSpeciesIndex(rateRuleVariable);
                hasOnlySubstanceUnits = dataSymbols.getFloatingSpeciesHasOnlySubstanceUnits()[idx];
                const uint& compIdx = dataSymbols.getCompartmentIndexForFloatingSpecies(idx);
                speciesCompartmentName = dataSymbols.getCompartmentId(compIdx);
                speciesCompartment = model->getCompartment(compIdx);
            }


            So for some reason roadrunner things S2 is a boundary species and S1 is not. Don't know why. 



Things today
--------------
- release notes
- Docs on backend
- git issues
- git branches
- performance stuff
- paper










Does the caching in LLJit respond to the caching flag? 



I've touched every aspect of RoadRunner
---------------------------------------
- Build documentation system
- built build system
- 


Things to do today
- start work on roadrunner paper
- algorithms on leetcode
- Data structures on leetcode 
- some graph theory on leetcode
- look more into potential uni course 



attachDataSet









Notes for Interview with Amsterdam Scientific Instruments
---------------------------------------------------------
They want me to talk them through a project or two. Options: 

- RoadRunner (currently writing paper for publication)
    - https://github.com/sys-bio/roadrunner
    - What is it? 
        - Library for execution and simulation of ODE models encoded in SBML. 
        - Widely used in the systems biology community. 
    - Build system
    - CI system
    - Docker for manylinux
    - multi language documentation system (http://sys-bio.github.io/roadrunner/). 
    - standardized the test system (with gtest)
    - Multi-language documentation system
    - Steady state solvers
    - Sensitivity solvers
    - pickleable roadrunner object 
        - Python's C API. 
    - New LLVM Jit compiler
    - RoadRunner hashmap for parallel compiles. 


- libOmexMeta (published 2021)
    - https://github.com/sys-bio/libOmexMeta
    - Publication (https://pubmed.ncbi.nlm.nih.gov/34132740/)
    - I am the sole developer. 
    - Built to community driven specification "OmexMeta v1.2"
    - library for annotating sbml models. 
    - 5 Layers. 
        - Layer 1: Redland C library which does the heavy lifting regarding RDF manipulation. Wrote a RAII wrapper around this for use in C++. 
        - Layer 2: The main C++ library. 
        - Layer 3: Thin C wrapper around the C++ library
        - Layer 4: In Python, load symbols from shared C library using ctypes python package
        - Layer 5: Prettify loaded symbols with OOP API. 
    - Each layer is fully tested 
    - Build system
    - CI system
    - Docker for manylinux
    - Multi-language documentation system (https://sys-bio.github.io/libOmexMeta ). 

- PyCoTools (published 2018)
    - https://github.com/CiaranWelsh/pycotools3.git
    - published (https://academic.oup.com/bioinformatics/article/34/21/3702/5001390)
    - Pure Python
    - docs https://pycotools3.readthedocs.io/en/latest/
    - library used for automating control of COPASI, biological modelling software. 
    - Increases parameter estimation throughput
    - Identifiability analysis vai profile likelihoods. 
    - Model selection, pick model topology with best fitting parameters. 


- PokerX
    - https://github.com/CiaranWelsh/PokerX
    - C++ texas holdem poker simulation engine. Modelled poker as a state machine.  
    - Still not completed, lots of edge cases that need catering for. 
    - Not sponsored, so not much time for this. 
    - Eventually aims to be used for reinforcement learning. 
    - Makes heavy use of coding to interfaces and mocking for perfectly independent unit tests. 

- Qualitative model fitting
    - https://github.com/CiaranWelsh/QualitativeModelFitting
    - Aims to be a unit testing like package for SBML/ODE models 
    - Here I wrote my own language using Python Lark parser
    - The language provides a description of expectation for a models behaviour. 
    - The library then validates/invalidates these descriptions.
    - https://qualitativemodelfitting.readthedocs.io/en/latest/runner.html. 


- Differential expression bootstrapping for confidence intervals (PhD thesis, Wafergen high throughput PCR data)
    - https://github.com/CiaranWelsh/WafergenPaper.git
    - Look at the FullDataSetBarGraphs.pdf to get an idea of the scale of the dataset
        - 9 cell lines, baseline, control and treated, 12 time points, 6 repeats. Then measured 72 genes by pcr in each condition. 


- RNA-seq bioinformatics pipeline on slurm based HPC cluster
    - https://github.com/CiaranWelsh/SingleCellBreastCancerData/tree/master/bash_scripts



class : 

    AnInt



class UnionFind{
public:
    
    UnionFind(int size) 
        : numberOfSets(size), 
        roots(std::vector<int>(numberOfSets)), 
        ranks(std::vector<int>(numberOfSets)){
            for (int i=0; i<size; i++){
                roots[i] = i;
                ranks[i] = 1;
            }
        }
    
    int findRoot(int x){
        if (x == root[x])
            return x;
        root[x] = findRoot(x);
        return root[x];
    }
    
    void makeUnion(int x, int y){
        int rootX = findRoot(x);
        int rootY = findRoot(y);
        if (rootX != rootY){ // they are different trees.
            if (ranks[x] > ranks[y]){
                // x tree is bigger
                // merge y into X
                root[y] = rootX;
            } else if (ranks[y] > ranks[x]){
                // y is bigger. Merge x into y
                root[x] = rootY;
            } else {
                // both are equal. Merge either into either. But increase ranks by 1 
                root[x] = rootY;
                ranks[y]++;
            }
            // if we've merged, we have one less disjoint set
            count--;
        }
    }
    
    bool connected(int x, int y){
        return findRoot(x) == findRoot(Y);
    }
    
private:
    std::vector<int> roots;
    std::vector<int> ranks;
    int numberOfSets;
}




SBML test suite
----------------
- need for searching tags. 



price 3.12 * x = $7,939,725,138 ; x = 2544783698.08
2,545,006,273 * 3.12 = 7,881,615,921




expected: https://www.funda.nl/huur/amsterdam/huis-42676432-spijtellaantje-5/
actual :  https://www.funda.nl/huur/amsterdam//huur/amsterdam/huis-42676432-spijtellaantje-5/





Contacted by email: 

https://www.funda.nl/huur/amsterdam/appartement-88047036-orteliusstraat-64-h/



27/01/2022
------------
- Do roadrunner multithreadded
- Look again at pysces
- Use amici Python front end. 


Hello, would it be possible to book a viewing? With thanks

Ciaran 





Things to do: roadrunner wide
- Build llvm on mac with M1 chip code/cmake. Don't write it myself, use the dedicatrd git branhc. 
    - Modify the source code to hard code the mac universal binaries flag. Create new release





- MacOS address santizer build and thread san builds. 








16/02/2022 - Start at ASI
=========================


Notes for 9:30 meeting
------------------------
- I tried to get the UI working on macos. Ran into problems - some of the tests failed and not sure why. 
- I tried again on windows. Some of the tests failed again but I was at least able to run Serval with the emulator and get the UI up and running. 

Other notes: 

- Problem with missing tpx3_analysis. I found instructions in the readme to copy a Python subpackage from a dependency project and rename it. This can/should be improved, whether by structural changes or by configuring Python Path. 
- add a requirements file (maybe a conda enviornment.yml) 
- the read me says to use "pip install ." but this failed for me on windows. 


Get in contact with Eric about meeting tomorrow and Eric hoffenberg on friday
- Eric hoffenberg, tomorrow in office. 
    - Get in contact. 
- Bruam. meet on Friday.  


Hello Eric, I hear that you are coming into the office tomorrow. I started work with ASI on Monday and I'd like to begin meeting people - would you like to schedule a time to meet me at all? On my end, I'm still trying to find a place to live and will be viewing a property at 10:30am but I'll be around from 11am. Good to "e-meet" you. Ciaran  



Hello Fei, I'm currently trying to figure out my living situation. So far I have tried to rent 4 different places and each time I was rejected in favour of somebody else. I was told that I could get an endorsement letter from my employer and this would increase my chances of finding somewhere. Would you be able to help me with this? Thanks

Ciaran 

p.s. I'm looking forward to meeting you properly





Hello Irene, I would like to make an offer on this apartment. I had a good conversation with Steven who seemed to think if I apply early and my documentation is good, then I stand a good chance of being accepted. Since this is my 5th time making an offer I'd like to do everything possible to make sure I'm accepted. Therefore, if you see any obvious mistakes that I've made, would you kindly let me know? 
So then, my offer. First a little bit about me. I'm British/Irish dual nationality here as an expat software engineer for Amsterdam Scientific Instruments (ASI). I started with (ASI) this week which is a little hectic because I also need to find a place to live. Before coming to Amsterdam, I ran my own UK based business called Biosoftware Development (its a small company but will come up in searches if you google it). Before this, I did a postdoc with some of my clients at the University of Washington, US and before that I did a PhD in computational biology in Newcastle, UK. My previous contract put me on 60K GBP a year whilst my new contract puts me on 70K EUR a year (with 8% holiday etc. and 30% ruling).
My preference would be a 1st March move in date, though I have some flexibility on this. I do not have any pets and I'd prefer to stay for 1 year initially, though if all works out well I'd like to stay longer. 
Attached to this email includes the following. My UK personal tax "self assessment" for last year
Signed contract with Amsterdam Scientific Instruments. I've asked them for an endorsement letter but they are unfortunately being a little slow on this. However, I will send it to you as soon as I get it. A screenshot of my vanguard ISA account, my transferwise account and my Celsius account. Collectively this shows that I can probably afford much of the year's rent upfront. My CV, just in case you're interested.I'm sure you can imagine that this information is very personal and therefore ask you not to share this with anyone. 


17-02-2022
=============

Morning meeting notes
-----------------------
- I decided to take the existing code and to try to disect it bit by bit. 
- Start: how the data is generated, i.e. the emulator. 
    - To get a better feel for what is going on I decided to make a simple server/client program in java and send some text through it. 
    - I can get this to work in a single program where one daemon thread is the server  another is the client. 
    - However I get connection refused issues when the server and client are in different programs. 


Regarding the tests
--------------------
- I think it would be better if we could set the emulator running during the setup phase
  of the tests so that developers do not need to manually set the emulator running. 
- Separation of integration and unit tests? 
- Broken test ApiSessionTest.simpleSession() on windows because of different line endings. 
    - Strip whitespace
- Many of the tests are dependent on having an emulator running. Currently (as I understand it) it is the dev's responsibility to start an emulator and before running the tests. It is easy however to pop the emulator start code in a setUp for a test fixture which prevents the other devs from thinking about it. 
- Is it standard practice for you guys to always manually run the emulator before running the tests? 


todo
----
Presentation for Monday morning on just me. 

Spoke to Fei. She says:
- fresh eyes. See anything I think can be improved - speak up. 
- Where are the raw data for emulators stored? 


Advice from a SO wizard on sockets: 

https://stackoverflow.com/questions/36272966/java-sockets-connection-refused-error/36273761?noredirect=1#comment125782830_36273761

perhaps you are trying to use a port < 1024, which is reserved and usually requires special privileges to use, or perhaps an internal firewall is blocking the access, or maybe you are trying to use a port which is already in use, or some other issue. If this app works for you using the hardcoded 8082 port, then running two separate processes for client and server should also work, as long as you are trying to run only one server on port 8082 at any one time.

if you would like a tutorial in sockets, the Oracle socket tutorial is good. You could study the source for the knock knock example from the tutorial, copy it into a local project, compile and run it and it should provide you with a client and server running in separate processes. GUI example for the knock knock app.


recap
-----
- Firmware exists on a chip. This is embedded code - proper low level code. We have an API 
to configure it. 
- The data is fired at the NIC, which is hardware inside the computer (not detector). The NIC recieved the packets of data where they are copied into the java environment at/in/by the UDPReciever. Once in the Java environment, they are not copied again but the same data is always referenced.
- The packets are either checked (old) or sorted (new) by the PackedChecker/PacketSorter. We know how many packets there should be and they are numbered. Therefore, we use this number as an array index for O(1) access. 
- The Ringbuffer is a data structure from a external library. As I understand it, it's purpoase is mainly in the orchestrating of parallel work. The RingBufferSubmitter gives the RingBuffer data at the start of its parallel pipeline. 
- Which is the work of assembling packets into frames. Each frame can be assembled in parallel, since there are no dependencies between packets. 
- There is a blocking operation that stops semi-constructed frames from progressing in the pipeline. Frames can only progress once completed.
- The MeasurementEventHandler and IntegrationHandler builds the complete image, consisting of all frames (?). 
    - They also are responsible for emitting to various channels, like a FileChannel. 

Questions for dev team
-------------------------
- When the emulator runs, which port are we using? 
- Where are the raw data that's served by the emulator stored? 



18-02-2022
==========
- I wrote a recap of the architecture and passed this on to Rick to check my understanding. 
- I've been playing around with the tests, mostly with ApiSession. 
  - Question, whilst you are developing, do you always manually set the emulator going? If so I think this is something that should be automated. In the end, it isn't customer facing so they won't see it. However, anything we can do to streamline the development process is a productivity win. 
- Unit/Integration separation?
- Where is the technical documentation

The rasnik pattern questions
----------------------------
- Is the rasnik pattern that we are using for a test image a stream of data or just a snapshot? 
    - If single image, are you worried that
    - 2D cellular automata can generate simple deterministic frame data

Suggestions
----------
- Move the tests that are under "main/.../tools/test" to "test/.../tools".
- Do we have only 1 test pattern? (the rasnik pattern). Is it worth having more?  
- An idea for another test pattern is a 2D cellular automata. This would produce a contineous stream of determinstic frames for testing. 



Cellular Automata plan
-----------------------
- Generate a contineous, deterministic stream of data?
- 2D or 1D. Start with 1D. Each frame adds a line to a 2D image, which is otherwise blank. 
- Rules are stored as an array. There are 8 situations, so each index refers to a particular situation. 
- Could even expose these test images to users which would give them the ability to load the test runs for training purposes? 



Ask Eric for where to start with preparation for Wednesday 

- understand python examples with Serval. 




Read up on fpga
Butbicket firmware software for megapixel software
peta linux 


Can be run from WSL on windows, linux or mac shell (I'm using WSL). I changed the source code manually in the dockerfile to update the miniconda link from this: 
    https://repo.anaconda.com/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh
to
    https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# find the docker directory
cd /mnt/d/roadrunner/roadrunner/docker/roadrunner-manylinux2014-base/

# build the docker image. The tag is the name of my dockerhub repo plus the 
# name of the docker image. For you, this might be luciansmith/roadrunner-manylinux2014-base. This will take a long time the first time you do it
# because we build gcc and llvm before roadrunner. 
docker build --tag ciaranwelsh/roadrunner-manylinux2014-base .

# now push to docker using the same tag you used to build. So for me its
docker push ciaranwelsh/roadrunner-manylinux2014-base

That's it. 














- Long term temp readout 


Ping Thorbjoern on teams. I didn't quite follow what you've asked. 

Add my name to list of things. 
What we are working on currently? 


- I've been looking at the code as much as possible. 
- I've began looking at the camera class. 


- I've had various meeting with people, like Eric and Bram. 
- I'm running the tests writing bits of code, using the various classes in Serval. 
- Mainly looking at Serval
- Thinking about creating a UML class diagram to help familiarize myself with the structure of the code. 



- What is the reason for 3 different packages? 
- I think the 3 layers (common, spidr and serval) would be better placed in the same subfolder. 

- Where are the docs foder? This seems missing. Also, many classes are missing docstrings. 
    - Docs autogenerated from source code. 

- I know the "common" package is often used, particularly in java project but I think it would be better to give the package a descriptive name so that just by looking you can understand a bit about what it does. In this case, perhaps pipeline would be suitable? 
- I've got the be careful about coming in and suggesting that things are "wrong", but I've been asked for suggestions for improvements. 
- Clearly I need to be careful because I'm not an expert on this codebase, but I dislike packages/subpackages called "common" because its not very descriptive 


WhatIsTheOverallNameOfTheSoftware?

- amscins
    - docs
        - Where are the docs? 
    - src
        - common
        - spidr
        - serval
    - test
        - common
        - spidr
        - serval


- Why is the JSONWriter/JSONReader under "common/.../image"?
- We've got a duplicate TestImage one under common/.../image and another under



Questions for them
-------------------
- How are you handling your documentation? API docs should at least be developers docs if not user facing. 
- What

maven javadoc 


- Do we use direct or non-direct buffers for packet data? 


        byte[] actual = retrieved.array();
        System.out.println(Arrays.toString(retrieved.array()));
        ArrayList<Integer> expected = new ArrayList<>() {{
            add(30);
            add(40);
            add(50);
            add(60);
            add(70);
            add(0);
            add(0);
            add(0);
        }};



Notes
----------------------------------
- Going through MeasurementPerformanceTest
- I didn't understand the Orientation. 
- Would be useful to have some docs in Pipeline. How would you use it to (for example) add 1 then 2, then 3, 4, 5 to a int ? These types of abstract little examples can be really insightful. 
- PipelineComponent and PipelineProducer classes are abstract. Mock these objects?
- Find the amscins.sharepoint website
- ATCP interface 
- ResourcePool would be useful for documenting

Classes used by Pipeline:
- ResourcePool                  - tested
- PipelineProducer              - abstract type, has one class which implements the interface
- Disruptor
- PipelineComponent
- PipelineEventHandler



- Maybe ResourcePool should be tested before Pipeline. 




23/02/2022
===========

Scrum
------
- Yesterday I spent time looking at the pipeline package in "common". 
- I started at the Pipeline class which is a composed of several other classes. I decided to take a note of the other classes and write some tests for the "leaf" classes. To this end I wrote unit tests for ResourcePool. Once I had figured out how it works, I also wrote documentation for it. 
- Also been looking at some documents sent through by Eric regarding the chip checking tests. 

Chip checking
--------------
- To turn these manual tests into automated tests, we need an expected result for each test to compare against. 
- For each test, it'd be good to have an example of the kinds of failures you can expect. 
- 









Chip checking
--------------
- Automate first part of testing procedure
- chip checker playground
-   ccplaygarden
- serval_toolkit, a python package for interfacing with serval. 
    - I think this should be a part of Serval. 


    - The submodule's idea does work and although a little unusual in Python does make sense, because we are not open source and do not want this package available via pip. 
    - I would have an "api's" folder under the serval repository
    - Serval repo
        - .idea
        - .gradle
        - common
        - serval
        - spidr
        - api
            - python
                - serval
                    - __init__.py
                    - serval.py
                - setup.py


ideas for the serval_python_api (serval_toolkit)
-------------------------------------------------
- We currently have a quite large and flat API
    - I want to make it more modular
- We are not using the structure dictated to us by serval 



Read up on "model view controller"


Always use IP v 4

Lookup IP and Netmask
Connect physical port to an ip address

1 read the api in manual. 

serval_playgarden repository
    - mpx3


jps command for seeing java proceses



24/02/2022
==========
- Yesterday I spent a little time looking at the python wrapper around serval, developed by Eric. I started making some basic improvements but stopped because I don't want to over engineer this library. It is my understanding that whilst useful internally, this is not customer facing code and really does not need to be perfect. 

- Yesterday I figured out how users are supposed to interact with Serval. Since I'm comfortable with this, I now need to figure out the specifics of the FAT tests to implement them via scripting. 


Find the documents that Eric send you regarding the tests

Todo
----
Ask somebody about the structure of sharepoint. 
Schema for the API? 
- remove comments from ResourcePool 



1pm meeting. Tpx4 software dev
------------------------------
- SErval needs to adapt to Tpx4
    - on two sidse, control and pipeline. 
    - Spidr4 

- Email Tista. 
    - holiday

- What does dacs stand for? 


Notes on examples
-------------------
- I was unable to `GET measurement/start` without first configuring `server/destination`. 
    - Example 3.5 in the Mpx3 docs 
        - uses `url = serverurl + '/destination'` for its url. Earlier in the document serverurl is defined as `http://localhost:8080` (or similar) and so this implies the user should use the url `http://localhost:8080/destination`. This is an incorrect endpoint and instead we should use `http://localhost:8080/server/destination`. This should be updated. 
        - Then, the PUT request as described in the docs fails with 
            ```
            Failed PUT request: http://localhost:8080/server/destination 400 : Failed mapping destination configuration: while trying to resolve 'Image[0]'. Issue: Format must be defined when the scheme is file. Supported formats: 'tiff', 'pgm', 'png'.
            ```
        - Adding `"Format": "tiff"` under the `Image` list failed with: 
            ```
            Failed PUT request: http://localhost:8080/server/destination 400 : Failed mapping destination configuration: No mode defined. Expected at least one mode in any channel.
            ```
        - Then I get
            ```
            Failed PUT request: http://localhost:8080/server/destination 400 : Failed mapping destination configuration: MPX3 does not support the mode null. Supported modes: 'count'.
            ```


24.02.2022
===========
- Yesterday I wrote my own little script for taking an image. I was able to collect a preview, but the preview was a black square. I'm still looking for the reason why I do not get the expected image back however.  
- Maurits - I don't have permission for the file that you tried to send me.
- Rick, you made some comments regarding my PR. These have been resolved in recent commits yesterday. 
- Discuss that I found an issue with the mpx3 docs. I put the issue on Jira. 
- When I started I was asked not to keep suggestions to myself. I have one: 
    - Propose idea for maintaining the docs by using latex code. 
        - Exery example should be a fully executable python program, including imports
- Also, does it make sense to have a default destination configuration? 
- Apologise ahead of time if I post an issue that isn't really an issue. 
- Today I intend to discuss some specifics with Ben and Eric about the FAT tests. 
    - I'm going to propose that we start by discussing a single test in detail and then letting me go away and write code for it. 
    - Then when its done, we resume, discuss, modify and move on if necessary. Rinse and repeat until its done. 
    - Initially it will take a little longer because I'll be putting in the framework, but this process will get quicker. Think like report generation is an unknown to me right now, though I have some ideas. 
 

Notes
------
What is TRPC? 
Do more reading on microscopy!

ImageJ
ImageMagik



holidays
---------
April 15th - 1st May   - 8 days holiday
June 21th to July 4th  - 10                 9 days left
december 27th     to Friday 6th Jan     uses the last 9 days.        

but could just go back to work on the 2nd jan. Better since it'll give me extra days throughout the year.            





Connect method
Acos - equalization procedure. 

FATTest abstract class
Is this something that we can set running and then leave it. Or do we want to run them manually? 

LED test wont be done for electron microscopes. 
There is an order to these tests. Equalization produces the bpc file and changes the dacs file. 
    - equalisation is somethign done by us. Customers will not need to do this. 

- java -jar serval... --experimental 


Equalisation is only Mpx3

DACs scan first. Then dacs tuning. Then equalisaions, whichmay modify some dacs settings. L

Find the implementation of the API so you can see what isn't customer facing

map reduce with a lambda. 

Some other meta data. standard deviation. Non responsive pixels. Find these. 


develop 


Things I am doing (Friday)
- Rebuild serval etc. with system wide java version. 
- Add jar files to bin directory of chip checker. 
- Build tool for spinning up and tearing down an emulator and serval instance per unit test so that we do not share state between tests. 
- build the optimize methods for dac_disc


26/02/2022
-------------

Command <|-- ServalCommand <|--

Command is used under the hood, not user facing code. 

Wrapper
-------

Emulator and Serval are both RunableServers. 
em = Emulator()
em.start()
em.stop()

serval = Serval()
serval.start()
serval.stop()   

Executable
    + start()
    + stop()

JavaExecutable(Execut) 
PythonExecutable


todo
----
- figure out how to build a zip distribution of java 
- create my own java gradle project
- Ask Rick how to configure the spidr::*emulators. 









When we do Popen we are running code in another python process

A running python program us a subprocess of PyCharm. When either PyCharm or the program is killed, the program stops and pid is not running. 

Using Popen runs the python program in a separate process, outside the scope of PyCharm. In this case, the main Python program spawns a new Pything program. The first python program is a child of PyCharm, but the second is a process in its own right. In the second case, closing PyChaem does not affect the running of the second program. After the commands are done with, the first pyton program is finished. 

It takes a little time for the java program to run. 



So I've been looking into building an envornment for automating FAT tests. I'm in the process of laying a foundation from which we can work from. At the moment this means wrapping Commands in little classes



30156

27/02/2022
----------
- manually run the emulator and then serval. Change the net and port respectivaly. 
- Look at failing PR
- 
ikea big overhanging light





28/02/2022
===========
- I've been developing a little bit of infrastructure around emulators and serval in python 
- The idea is that we will have a little library containing calls to the various FAT tests that we want.
- I want unit tests for this code and to do so we need each test to spin up its own emulator/serval pair. 
    - With out this there are state dependencies between tests which is bad.  
- so. I'm currently building tool for running serval and emulators in separate processes as daemons. 


Config: 

C:\Miniconda3\envs\py39\python.exe C:\Users\Ciaran\AppData\Local\JetBrains\Toolbox\apps\PyCharm-P\ch-0\213.6777.50\plugins\python\helpers\pycharm\_jb_nosetest_runner.py --target serval_tests.py::APITests.test_get_bpc_file
Testing started at 10:23 ...
Launching Nosetest with arguments C:\Users\Ciaran\AppData\Local\JetBrains\Toolbox\apps\PyCharm-P\ch-0\213.6777.50\plugins\python\helpers\pycharm\_jb_nosetest_runner.py serval_tests.py:APITests.test_get_bpc_file in D:\AmsterdamScientificInstruments\ccplaygarden\test


Process finished with exit code 0
emulator pid: 2016
serval pid: 7176
{'Detector': {'Chips': [{'Adjust': None,
                         'DACs': {'Cas': 178,
                                  'DAC_DiscH': 85,
                                  'DAC_DiscL': 79,
                                  'DAC_test': 100,
                                  'Delay': 50,
                                  'Disc': 125,
                                  'Disc_LS': 100,
                                  'FBK': 180,
                                  'GND': 131,
                                  'Ikrum': 10,
                                  'Preamp': 150,
                                  'RPZ': 255,
                                  'Shaper': 150,
                                  'Shaper_Test': 0,
                                  'TP_BufferIn': 128,
                                  'TP_BufferOut': 4,
                                  'TP_REF': 140,
                                  'TP_REFA': 300,
                                  'TP_REFB': 300,
                                  'Threshold[0]': 42,
                                  'Threshold[1]': 44,
                                  'Threshold[2]': 46,
                                  'Threshold[3]': 48,
                                  'Threshold[4]': 50,
                                  'Threshold[5]': 52,
                                  'Threshold[6]': 54,
                                  'Threshold[7]': 56},
                         'PixelConfig': '...'},
                        {'Adjust': None,
                         'DACs': {'Cas': 178,
                                  'DAC_DiscH': 85,
                                  'DAC_DiscL': 87,
                                  'DAC_test': 100,
                                  'Delay': 50,
                                  'Disc': 125,
                                  'Disc_LS': 100,
                                  'FBK': 180,
                                  'GND': 131,
                                  'Ikrum': 10,
                                  'Preamp': 150,
                                  'RPZ': 255,
                                  'Shaper': 150,
                                  'Shaper_Test': 0,
                                  'TP_BufferIn': 128,
                                  'TP_BufferOut': 4,
                                  'TP_REF': 140,
                                  'TP_REFA': 300,
                                  'TP_REFB': 300,
                                  'Threshold[0]': 42,
                                  'Threshold[1]': 44,
                                  'Threshold[2]': 46,
                                  'Threshold[3]': 48,
                                  'Threshold[4]': 50,
                                  'Threshold[5]': 52,
                                  'Threshold[6]': 54,
                                  'Threshold[7]': 56},
                         'PixelConfig': '...'},
                        {'Adjust': None,
                         'DACs': {'Cas': 178,
                                  'DAC_DiscH': 87,
                                  'DAC_DiscL': 83,
                                  'DAC_test': 100,
                                  'Delay': 50,
                                  'Disc': 125,
                                  'Disc_LS': 100,
                                  'FBK': 180,
                                  'GND': 131,
                                  'Ikrum': 10,
                                  'Preamp': 150,
                                  'RPZ': 255,
                                  'Shaper': 150,
                                  'Shaper_Test': 0,
                                  'TP_BufferIn': 128,
                                  'TP_BufferOut': 4,
                                  'TP_REF': 140,
                                  'TP_REFA': 300,
                                  'TP_REFB': 300,
                                  'Threshold[0]': 42,
                                  'Threshold[1]': 44,
                                  'Threshold[2]': 46,
                                  'Threshold[3]': 48,
                                  'Threshold[4]': 50,
                                  'Threshold[5]': 52,
                                  'Threshold[6]': 54,
                                  'Threshold[7]': 56},
                         'PixelConfig': ...},
                        {'Adjust': None,
                         'DACs': {'Cas': 178,
                                  'DAC_DiscH': 85,
                                  'DAC_DiscL': 76,
                                  'DAC_test': 100,
                                  'Delay': 50,
                                  'Disc': 125,
                                  'Disc_LS': 100,
                                  'FBK': 180,
                                  'GND': 131,
                                  'Ikrum': 10,
                                  'Preamp': 150,
                                  'RPZ': 255,
                                  'Shaper': 150,
                                  'Shaper_Test': 0,
                                  'TP_BufferIn': 128,
                                  'TP_BufferOut': 4,
                                  'TP_REF': 140,
                                  'TP_REFA': 300,
                                  'TP_REFB': 300,
                                  'Threshold[0]': 42,
                                  'Threshold[1]': 44,
                                  'Threshold[2]': 46,
                                  'Threshold[3]': 48,
                                  'Threshold[4]': 50,
                                  'Threshold[5]': 52,
                                  'Threshold[6]': 54,
                                  'Threshold[7]': 56},
                         'PixelConfig': '...'}],
              'Config': {'BiasEnabled': True,
                         'BiasVoltage': 12,
                         'BothCounters': False,
                         'ChainMode': 'NONE',
                         'ChargeSumming': False,
                         'Colour': False,
                         'DetectorOrientation': 'UP',
                         'ExposureTime': 0.1,
                         'Fan1PWM': 0,
                         'Fan2PWM': 0,
                         'GainMode': 'SHGM',
                         'IDelayConfig': [15, 15, 15, 10],
                         'LogLevel': 1,
                         'PixelDepth': 1,
                         'Polarity': 'Positive',
                         'TriggerIn': 0,
                         'TriggerMode': 'CONTINUOUS',
                         'TriggerOut': 0,
                         'TriggerPeriod': 0.1,
                         'nTriggers': 0},
              'Health': {'AVDD': [1.5, 0.0004, 0.6],
                         'BiasVoltage': 11.97509765625,
                         'ChipTemperatures': [54, 89, 89, 89],
                         'FPGATemperature': 40.0,
                         'Fan1Speed': 0,
                         'Fan2Speed': 0,
                         'LocalTemperature': 40.0,
                         'VDD': [1.5, 0.0004, 0.6]},
              'Info': {'Boards': [{'ChipboardId': '51000039',
                                   'Chips': [{'Id': 680, 'Name': 'W0002_J08'},
                                             {'Id': 681, 'Name': 'W0002_J09'},
                                             {'Id': 682, 'Name': 'W0002_J10'},
                                             {'Id': 683, 'Name': 'W0002_J11'}],
                                   'IpAddress': '127.0.0.10',
                                   'PortNumber': 8192}],
                       'ChipboardID': '51000039',
                       'ClockReadout': 125.0,
                       'FW_version': '18100200',
                       'IfaceName': 'Spidr',
                       'MaxPulseCount': 2147483647,
                       'MaxPulseHeight': 1.0,
                       'MaxPulsePeriod': 34.35973836,
                       'MpxType': 5,
                       'NumberOfChips': 4,
                       'NumberOfRows': 512,
                       'PixCount': 262144,
                       'RowLen': 2,
                       'SW_version': '19081915',
                       'SuppAcqModes': 63,
                       'TimerMaxVal': 34.35973836,
                       'TimerMinVal': 8e-09,
                       'TimerStep': 8e-09},
              'Layout': [{'Orientation': 'RtLBtT', 'X': 1, 'Y': 0},
                         {'Orientation': 'RtLBtT', 'X': 0, 'Y': 0},
                         {'Orientation': 'LtRTtB', 'X': 0, 'Y': 1},
                         {'Orientation': 'LtRTtB', 'X': 1, 'Y': 1}]},
 'Measurement': {'Config': {'Corrections': {'Multiply': None}}, 'Info': None},
 'Server': {'Destination': None}}
.
----------------------------------------------------------------------
Ran 1 test in 1.322s

OK





create a dedicated DACs class 



how do I communicate with the emulator directly?


When error - were not stopping the processes 

emulator: process 6164 is java but it has another process attached to it, 3064
serval:     21164 and 31324


from __future__ import annotations
import json
from copy import deepcopy

import requests

from _requests import get_request, put_request, is_busy
from _constants import (
    BPC_CONFIG_FILE, DACS_CONFIG_FILE
)
from time import sleep
import logging
from typing import *
from re import findall
from _exception import NotInitializedException
from _runner import Runner
from _command import JavaCommand
from _constants import SERVAL_JAR
from _exception import ServalException
from pprint import pformat
from contextlib import contextmanager

logger = logging.getLogger(__file__)


def check_is_instance(variable, type):
    if not isinstance(variable, type):
        raise TypeError(f"variable \"{variable}\" is not of type {type}")


class Serval(Runner):

    def __init__(self, port: int = 8080, dacs_file: str = DACS_CONFIG_FILE, bpc_file: str = BPC_CONFIG_FILE):
        check_is_instance(port, int)
        check_is_instance(dacs_file, str)
        check_is_instance(bpc_file, str)

        # which port to run Serval on?
        self._port = port

        # the url and port used for requests
        self._url = f"http://127.0.0.1:{port}"


        # abstraction around a java command for running serval
        self._cmd = JavaCommand(daemon=True, optional_value_prefix="--", optional_value_separator="=") \
            .jar(SERVAL_JAR) \
            .add_flag("experimental") \
            .add_optional_argument("httpPort", port)

        # the process id used for running serval in separate process
        self.pid = None

        self.start()
        logger.info(f"Serval is running on: {self._url}")

        # # upload dacs configuration
        # self.set_dacs_config(dacs_file)
        #
        # # upload pixel configuration
        # self.set_pixel_config(bpc_file)

    def __str__(self):
        response = self.get(f"*")
        return pformat(response.json())

    def is_busy(self) -> bool:
        """returns True if serval is busy"""
        # do not use this method in get/put methods --> circular
        return is_busy(self._url + "/*")

    def wait_for_request(self, poll_every: float = 0.1) -> None:
        """Waits for a serval request to complete before returning control to main thread

        Args:
            poll_every: check if serval is busy this after this many seconds

        Returns:

        """
        while self.is_busy():
            logger.info(f"sleeping for {poll_every} seconds")
            sleep(poll_every)

    def get(self, url:str, params:dict=None, expected_status:int=200, wait:bool=True) -> requests.Response:
        """wrapper around requests.get"""
        if url.startswith("http://"):
            raise ValueError("Invalid input. Url should omit the ip address. I.e. \"dashboard\" is valid but \"http://localhost:8080/dashboard\" is not")
        if self._url.startswith("/"):
            self._url.removeprefix("/")
        return get_request(f"{self._url}/{url}", params=params, expected_status=expected_status, wait=wait)

    def put(self, url, data, params=None, expected_status=200, wait=True) -> requests.Response:
        """wrapper around requests.put"""
        if url.startswith("http://"):
            raise ValueError("Invalid input. Url should omit the ip address. I.e. \"dashboard\" is valid but \"http://localhost:8080/dashboard\" is not")
        if self._url.startswith("/"):
            self._url.removeprefix("/")
        return put_request(f"{self._url}/{url}", data=data, params=params, expected_status=expected_status, wait=wait)

    @staticmethod
    @contextmanager
    def run(port=8080, dacs_file=DACS_CONFIG_FILE, bpc_file=BPC_CONFIG_FILE):
        serval = None
        try:
            serval = Serval(dacs_file=dacs_file, bpc_file=bpc_file, port=port)
            yield serval
        finally:
            serval.stop()

    def start(self) -> Serval:
        """Start instance of serval

        Serval is run in a new process outside the current Python scope.
        This means that when the current Python program ends, the process
        running Serval continues.
        """
        if not self.is_connected():
            self._cmd()
            if not self.is_connected():
                raise ServalException("Could not connect to serval")
            self.pid = self._cmd._proc.pid
        return self

    def stop(self) -> Serval:
        """Kill the current process that is running Serval"""
        self._cmd.kill()
        return self

    def is_running(self) -> bool:
        """Returns True is the process id that was used for running serval is still running

        This is not the same as being connected to serval, because its possible that the process
        is running an instance of serval that has errored, i.e. no connection.
        """
        return self._cmd.is_running()

    def is_connected(self):
        """Checks for viable connection to serval.

        Internally this uses a GET request to serval to verify that we can successfully
        send requests.
        """
        try:
            self.get("/dashboard")
        except ServalException as e:
            return False
        except requests.ConnectTimeout as e:
            return False
        except requests.ConnectionError as e:
            return False
        return True

    def set_pixel_config(self, bpc_file) -> str:
        logger.debug("loading pixel configuration")
        response = get_request(
            url=f"{self._url}/config/load",
            params=dict(format="pixelconfig", file=bpc_file),
            expected_status=200
        )
        logger.debug("pixel configuration loaded")
        return response.text

    def get_pixel_config(self):
        print(self)

    def set_dacs_config(self, dacs_file) -> str:
        """

        todo consider having a DACs class which would give finer grained
        control of dacs to the user. Do not implement until needed.
        Args:
            dacs_file:

        Returns:

        """
        logger.debug("loading dacs configuration")
        response = get_request(
            url=f"{self._url}/config/load", params=dict(format="dacs", file=dacs_file),
            expected_status=200
        )
        logger.debug("dacs configuration loaded")
        return response.text

    def get_dacs(self) -> dict:
        logger.debug("gettings dacs configuration")
        response = get_request(
            url=f"{self._url}/detector/chips", expected_status=200
        )
        return response.json()

# def is_init() -> bool:
#     """Returns true of dacs and bpc files have been successfully uploaded"""
#     return IS_INITIALIZED == True
#
#
# def _fail_if_not_init() -> None:
#     """raise error if not initialized"""
#     if not IS_INITIALIZED:
#         raise NotInitializedException("Call the init_device() method")
#
#
# def is_connected():
#     pass
#
#
# def tunedac(GND: int = 650, FBK: int = 900, Cas: int = 850) -> Dict[str, int]:
#     """Run the tunedac function in serval
#
#     Args:
#         GND: target GND value in mV
#         FBK: target FBK value in mV
#         Cas: target Cas value in mV
#
#     Returns: tuned values.
#
#     """
#     _fail_if_not_init()
#     DAC_TARGETS = {'GND': GND, 'FBK': FBK, 'Cas': Cas}
#     response = get_request(f"{self._url}/detector/tunedac", params=DAC_TARGETS)
#     match = findall("Tuned (.*) to (\d*) mV", response.text)
#     logger.info(response.text)
#     return {k: int(v) for k, v in match}
#
#
# def get_detector_config() -> Dict[str, Any]:
#     """query the current detector config"""
#     return get_request(f"{self._url}/detector/config").json()
#
#
# def set_detector_config(**kwargs):
#     """Set the parameters found under `/detector/config`.
#
#     Give the values as arguments (`key = value` combination).
#     If an invalid key is given, the other keys
#     """
#     detector_config = get_detector_config()
#     new_detector_config = deepcopy(detector_config)
#
#     for key, value in kwargs.items():
#         # Loop over all the (key, value) pairs given and change them in the config.
#         # If an invalid key is given, give a warning but still continue for the other parameters.
#         if key not in detector_config.keys():
#             raise ValueError('Invalid parameter for detector config: {}. Valid keys: {}'.format(key, list(
#                 detector_config.keys())))
#         else:
#             new_detector_config[key] = value
#
#     # Final check: if there are no changes, do not upload the new config to save time
#     if new_detector_config != detector_config:
#         put_request(f'{self._url}/detector/config', data=json.dumps(new_detector_config))
#     else:
#         logging.debug('No changes in detector config, all values are already as requested.')
#
#
# def optimize_dac_disc_lower():
#     """Optimize the lower threshold"""
#     _fail_if_not_init()
#     response = get_request(f'{self._url}/detector/optimize/DAC_DiscL')
#
#     # response = get_request(f'{SERVAL_URL}/measurement/histogram')
#     # print(response.json())
#
#
# def optimize_dac_disc_higher():
#     """Optimize the higher threshold"""
#     _fail_if_not_init()
#     get_request(f'{self._url}/detector/optimize/DAC_DiscH')

how you feel physically, mentally and whats your attitude/vibe?









01/-3/2022
============
- why d we use a get request for uploading settings file. To me it sounds like a put request
- eveything returned from serval is None
- Why is everything returned from serval None?
    - Maybe its because serval is not connected to an emulator? 
    - Is there a serval command we can use to check if it has a detector or emulator on the other end? 
- There's a problem, serval is not connecting to the emulator when I spin them up in new processes. 
- The emulator spin up happens in a new isolated process but takes time to get going. Meanwhile the main python thread continues to execute, immediately spins up a serval instance which fails to connect to the emulator

- What is the best strategy to communicate from emulator to python that the emulator is ready to be connected to? 
- Then I'll be able to move on to uploading config files and
- Catch this error in Serval. 


- p.communicate? 


```
ASI is growing!
This month we welcome two new colleagues to our team 🎉 🎉
Today we catch up with @..., one of our #NewHires
Hi …! Tell us a bit about yourself
How would you describe your first impressions of ASI in 3 words?
What were some of the highlights of your time at ASI so far?
Can you tell us about your aspirations & ambitions moving forward?
[headshot] tagged
#newhires #ASI #growth #welcometotheteam
```

I've got an emulator running and we cannot create a connected serval? So we need to wait for serval? 

So check 


1pm meeting
------------
Chip checking
    Building a library. Foundations include running serval/emulators from python. 

I'm mindful that you are on a clock so I'll just say I'm laying down some foundations for a chip checking library. If Eric wants a more indepth update perhaps we can talk afterwards. 




02/03/2022
===========

Morning meeting
----------------
- Continued progress with building some tools to make FAT testing easy. 
- Started building uml to help explain library design 



- Production test suite
- PTS
- Dependency tree


The manner in which I said oh that hysterisis is bistability just fell out. I kind of said it a bit abruptly, and arrogantly which was a mistake. The right approach was - "Isn't that bistability". Either way, whoops. Then later when I said to eric that he's missed everything, that was potentially rude of me. So what my manners when meeting with people. 




03/03/2022
----------
- We had a good discussion yesterday regarding chipchecking. I proposed a plan to Maurits, Eric and Ben. This plan involves building library dedicated to chipchecking which will provide an abstract class that can be overriden for each chip checker test. 
- I've began writing a temperature checker. The complication is that we want it running for a set time and we want to sample at intervals. So, yesterday I wrote an Interval class that uses threads


Okay, so I have a problem in that my sampler doesn't give me the correct number of samples. If I set a timer for 10 seconds, to do a task every 1 second that I expect 10 samples. However, because execution naturally takes time, we are loosing samples. 
So what if I run one thread separately for timer? 


Report stuff
--------------
There are a lot of different ways I could do this. 
    - Pandoc could be a useful tool. Its written in Haskell but has a python API. It uses an AST for representing elements of a document. The use of an AST is an interesting idea. It means that we can render the AST using any format we like, Markdown, latex, html, whatever. 
    - We could create our own AST. We've had this idea before in the form of creating an xml document out of our results. 
    - However, then we get into the terrortory of serializing the results from these devices. This should form part of a much larger discussion. 
        - For instance, what do we currently do? Do we have any existing report generation tools? Is this something you would be interested in developing? 
        - If yes, it's something we could put our heads together to come up with a standardized object model for representing this data. 
    - Could also use the json serializable idea. 
    - We could use a website / html
    - We could use plotly/dash for generating an interactive web app per report (something I've used before)
    - I wanted to use markdown, but its a bit limited. So then I thought of html. Then html can be fairly easily convertd to other formats if we want. 
    - 


- I realised there are a lot of ways to generate a report from python. There are many frameworks and countless libraries. So, I want to store the data in an intermediary json structure and then (eventually) have multiple ways of rendering. F











Section Name: Local Temp Check
===============================
A paragrargah about local temp check

<figure> 


Another Check
=============



30 kg - L = 130 W = 30 H = 80

60 + 160








Feb and March salary the rest dividends

if the write method returns a document section then the document can be a list of sections. with append etc.

doc section is a list of DocElements!

- add iterator methods to document
- then continue to test writer

Mock presentation for work guys
-

Hi Thom, I have the signed contract now, Susan dropped it off... And like I say, I have the link and filled in the forms a few days ago, I just didn't get any confirmation email from internet. 

GB 65 REVO 00997079409992


08/03/2022
==========

Morning meeting
------------------

- I have finished first draft of the first test. The test is deliberately basic as I want to consult more with Ben and Eric to get the contents of the test correct. 
- But, we have a framework which we can use as a basis for production tests. New tests are created by subclassing the "ProductionCheck" class and implementing some methods. 
- Today is about project management stuff. 
    - I'll create a setup.py script.
    - Set up CI platform
    - Configure a documentation website (offline) or online???
    - Write documentation
    - Look into creating a private pip or conda repository. 


- Get claudia
- reply to Susan
- response to sylvia 
- 

> Hi …! Tell us a bit about yourself
Hello I'm a British biochemist, systems biologist and software developer who's just moved to Amsterdam to work with the software team at Amsterdam Scientific Instruments. 

> How would you describe your first impressions of ASI in 3 words?
Smart, friendly and driven

What were some of the highlights of your time at ASI so far?
Getting covid in the first week. 

Can you tell us about your aspirations & ambitions moving forward?
> Learn as much as I can about the hardware and software.  


Yes I perhaps got a little trigger happy with this. 


CI
--
- Install gradle java and conda in python enviornment
- Install chipchecker
- Run chipchecker tests


Build a proof of concept private pip or conda channel


        p = subprocess.Popen([find_command, "java"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = p.communicate()
        stdout: str = stdout.decode()
        stderr: str = stderr.decode()
        if stderr != "":
            raise ValueError(stderr

gBQ4SJRzMg7YWmBtBwTH

synthetify
fran and shaun


Guys, I've been thinking about a branching strategy for the chipchecker project. I've created a new branch called "main" which is our default branch. When cloned, the project is by default on the "main" branch. We should then do our work on feature branches off of the "main" brach and merge into the "main" branch via pull request.  





gBQ4SJRzMg7YWmBtBwTH




Okay, so we could have inf many checks prepended like "test_" that return bool


10/03/2022
============

Scrum
-----
- I've set up the CI so that the tests run with coverage. 
- Augmenting the structure of chipchecking library to encapsulate checks on the data acquired from the detector. 
- I need to begin setting aside some time for better understanding what these detectors do and how they are made. Clearly, this is going to take a long time and I'm willing to put effort into it. However, it will go smoother with a little guidance in what to read. So, starting at the begining what should I begin learning? 

For me it is unknown what I need to know to understand these devices. 

But I do not want to do it alone. I want to ask Maurits if he can suggest starting points for a crash course in the background information that I need. 


- Access to real output data from tpx and mpx


- Learn enough about the underlying physics to be able to formulate scientific questions of my own and investivate them using the detectors. This will put me in the right mind set to develop software for our customers. 






find out how to do has_pixel_config using serval api directly. 





41.6441 Sol
41.6441 Sol

11/03/2022
===========

Book holidays 
    - Done for Sardinia
    - Need to do for Easter
Message landlady about water pressure and smell
message Thom about internet
Look into buying phone - Virgin credit? hmm
Ask cols to walk me through how leverage works - Live interaction. 

Scrum
-----
- Built a way to do checks on production checks.
    - Brings up the question of whether I should just inherit from unittest.TestCase. 
- Might work really well. 
    - Report generation may already be built. 
    - 


- Consider whether to reuse unittest
- Need to fix the serval problem. 

Meeting with Jord
-----------------
- My contract says 27 days of holiday, which is 27*8=216 hours, but I have 191 hours in felix
- First I've got to fix this problem with serval connection under some conditions, which is hard because they don't exist when you run a test on its own. So its a matter of trying to reproduce the problem, writing a new test for it and fixing the bug. 
- Get dacs uploaded only once. Need a way to check if dacs uploaded. 


Problem where using Emulators too quickly causes a connection issue. Adding a time delay works, but its quite a blunt instrument since it add artifical overhead in lots of cases for no reason.

ould it be that I need to wait for put requests to complete?    

Serval should be a singleton. 

When we are spining up two instance of the emulator, are we first detecting whether one already exists? Maybe emulators should also be a singleton. 

- Create a singleton metaclass. 
- Test it
- Use it on emulator and maybe serval. 





Can be a little confusing now. 
Out base ProductionCheck now has two additional methods: 
    - _collect_check_functions
    - _run_check_functions
Our ChipChecker tool 


subprocess.poll
Spend more time looking at accos

can the "retryingg" decorator be useful here? 


How can I make serval wait until connected?



GET


/detector/list
/detector/connect
/detector/disconnect
/detector
/detector/info
/detector/health
/detector/layout
/detector/config
/detector/chips
/detector/chips/<chip number>
/detector/chips/<chip number>/dacs
/detector/chips/<chip number>/pixelconfig 
/detector/chips/<chip number>/pixelconfig?format=bpc
/detector/chips/<chip number>/mask/<row>/<column>
/detector/rotate?reset&flip=horizontal&direction=right


PUT
/detector
/detector/config
/detector/chips 
/detector/chips/<chip number>
/detector/chips/<chip number>/dacs
/detector/chips/<chip number>/pixelconfig
/detector/chips/<chip number>/pixelconfig?format=bpc
/detector/chips/<chip number>/mask/<row>/<column>


GET
/server 
/server/shutdown
/server/destination

put
/server/destination



14/03/2022
===========

Weekly monday morning meeting
------------------------------
- We have the beginings of a library that we'll be able to use for chip checking. 
- Built in an extendable way and insipred by unit tests. 
- We are in a position now where Eric and Ben are getting their hands dirty with the code. 
    - They will be able to develop new tests which should fit in with the framework that I've built. More "Bricks" to process. 

Scrum
------
- I have a problem under some conditions where serval drops the connection. Connection reset by peers. Time delay solves the problem, but blunt instrument. 
- Turned my Serval and Emulator objects into a "OneAtATime", which behaves like a singleton when on but you can turn off the singleton. 
- Now trying to implement my requests in a new thread so that I can wait for it to complete before continuing. Though I'm not convinced that this will work. 



Understand how acquisition works. Looks at the Mpx3 hardaware docs. 
    - Figure 7

- Eletron microscope. 
- High energy particle physics
- Electronics
- What is in the FPGA
- 



- i need to be able to start capturing with Serval / emulator



if a serval instance gets deleted and


create a registered dataclass. Then you have the list of all dataclasses. 


rememeber the key to get betterperf


reduce the number of modules to search by only looking is chipcheckers

Could I use a queue? Or stack? 

dct = {'Dataclass2': Dataclass1(s='a string', i=40, f=0.766)}

needs to be 

dct = {'Dataclass2': {"dataclass1":Dataclass1(s='a string', i=40, f=0.766)}}


15/03/2022
===========
- Getting a BSN in a couple of days. 
- Need to find my birth certificate. 
- 

Scrum
-----
- I began building some tools to make json encoding and decoding easier. 
    - Encoding is done with an extra variable for the Type. 
    - Decoding searches the list of currently loaded modules (from chipchecker library only) for the class and instantiates it with the data
- Building a ni

- Swagger


First need to download state from 


- If the dataclasses are going to be persistant then use the has of the class and serialize it. 



Software meeting
-------------------
- Making good progress 
- I have the framework largely in place and its ready for fleshing out. 
- I'm currently working on 


Instead of uploading dacs from a file I would find it useful if we could update the dacs individually. i.e selet chip and setting. 


16/03/2022
=============

Scrum
-----
- The dataclass is in use and being used to hold destination data in chipcheckers
- The command to upload dacs requires a dacs file. This is useful sometimes, but sometimes we do not want to write to file before uploading to serval. Instead, it would be good to be able to encode the data in the url in the case of a get or as data in case of the put. 


Meeting with Maurits
----------------------

- Have you thought about using Jython? 
- When/how/who holiday approval? I want to book things. 


Chipchecker meeting
----------------------
- I want to start writing serious chipchecking tests. 
- It would be helpful to get some input







Sol
16/03/2022: 43.054570752



    @staticmethod
    def prune_tree(data: Dict, key: str, inplace: bool = False) -> None | JSONSerializableDataclass:
        """Helper method for removing a key from a dataclass/json structure

        When inplace=True, data is modified inplace. Otherwise, a copy of data is made
        and the return value is the new data with all instances of keys removed

        Args:
            data: (possibly nested) dict. Can be produced from `JSONSerializableDataclass.to_json_dict`.
            key: the name of the key to prune
            inplace: When true, modifies data inplace and return is None. When False
                     a copy is made before modification and the return value is the
                     modified dict.
        """
        # todo make key a list to remove multiple keys at the same time.
        data = data if inplace else deepcopy(data)

        if isinstance(data, dict):
            for k in list(data.keys()):
                if k == key:
                    del data[key]
                else:
                    JSONSerializableDataclass.prune_tree(data[k], key)
        elif isinstance(data, list):
            for item in data:
                JSONSerializableDataclass.prune_tree(data=item, key=key)
        return None if inplace else data




    @staticmethod
    def prune_tree(data: Dict, key: str, inplace: bool = False) -> None | JSONSerializableDataclass:
        """Helper method for removing a key from a dataclass/json structure

        When inplace=True, data is modified inplace. Otherwise, a copy of data is made
        and the return value is the new data with all instances of keys removed

        Args:
            data: (possibly nested) dict. Can be produced from `JSONSerializableDataclass.to_json_dict`.
            key: the name of the key to prune
            inplace: When true, modifies data inplace and return is None. When False
                     a copy is made before modification and the return value is the
                     modified dict.
        """
        # todo make key a list to remove multiple keys at the same time.
        _data = None

        if inplace:
            _data = data
            assert id(data) == id(_data)
        else:
            _data = deepcopy(data)
            assert id(data) != id(_data), f"id(data) == id(_data): {id(data)} == {id(_data)}"

        if isinstance(data, dict):
            for k in list(data.keys()):
                if k == key:
                    del data[key]
                else:
                    JSONSerializableDataclass.prune_tree(data[k], key, inplace=inplace)
        elif isinstance(data, list):
            for item in data:
                JSONSerializableDataclass.prune_tree(data=item, key=key, inplace=inplace)
        return None if inplace else data






















    @staticmethod
    def prune_tree(data: Dict, key: str, inplace: bool = False) -> None | JSONSerializableDataclass:
        """Helper method for removing a key from a dataclass/json structure

        When inplace=True, data is modified inplace. Otherwise, a copy of data is made
        and the return value is the new data with all instances of keys removed

        Args:
            data: (possibly nested) dict. Can be produced from `JSONSerializableDataclass.to_json_dict`.
            key: the name of the key to prune
            inplace: When true, modifies data inplace and return is None. When False
                     a copy is made before modification and the return value is the
                     modified dict.
        """
        # todo make key a list to remove multiple keys at the same time.
        # data = data if inplace else deepcopy(data)
        _data = None

        if inplace:
            _data = data
            assert id(data) == id(_data)
        else:
            _data = deepcopy(data)
            assert id(data) != id(_data), f"id(data) == id(_data): {id(data)} == {id(_data)}"

        if isinstance(_data, dict):
            for k in list(_data.keys()):
                if k == key:
                    del _data[key]
                else:
                    JSONSerializableDataclass.prune_tree(_data[k], key, inplace=inplace)
        elif isinstance(_data, list):
            for item in _data:
                JSONSerializableDataclass.prune_tree(data=item, key=key, inplace=inplace)
        return None if inplace else _data


use binary search for locating modules. Cache the modules on first find. 








Hi Jord, I had a couple of admin type questions that I was saving for our bi-weekly meeting tomorrow - however I read that you will not be in so I've jotted them down in this email. 
The first is that I was paid towards the end of last month, but I can't seem to find the corresponding payslip on Felixx. Do you know where I can find it?
The second is that I have requested holiday time on Felixx between 19th April and 29th April. I realised that we haven't discussed these dates so could you let me know whether its going to be problematic for me to be away over this period? I haven't booked yet so these dates are not set in stone. But also I haven't booked yet and will need to do so soon. 
(Also
ThanksCiaran 

Hi Jord, I am going now to get my BSN number. I'm free to talk later if you want/have time, I will be back for 3:30 / 4pm. In case you didn't have time, there were a couple of auxillary questions I had. 





17/03/2022
==========
- Getting a BSN today
- Where is birth certificate ? 


Scrum
-----
- Today I'll go to get a BSN number. 
- Building detector config dataclass
- Recursive algorithm for pruning json tree


- Continuing with chipchecking library. 
    - Dataclass serialization. 
    - Mechanism for handling data used in communication with serval 
    - Serialize type data. 
        - for deserialization
    - 


- TriggerDelay issue
- Merge the pull request in serval 
- Read Figure 7 from hardware documentation 

Work stuff
----------
- Singleton but only when serval/emulators are in the ON position
- data handling
    - Serialization code. Very general. Can serialize/deserialize any dataclass. 
- Could really do with more input from Eric and Ben regarding specifics of tests. 
    - Haven't yet written details of actual useful FAT tests, but we are ready for building them
- Currently trying to build code to actually take a image and preview from the emulator/sreval. 
- Meeting with Siamack next wednesday for a tour of the FPGA dev cycle.
- Begining to look towards another project. Perhaps learning more about the Java code base. 

Non work stuff
---------------

The first one is that I was paid towards the end of last month, but I cannot locate the payslip on Felixx. Do you know how I can access it? (I've found the payslips tab but the list is empty).

The second is that I've requested holiday between 19th April and 29th April, but I realised that we haven't discussed it yet and so I wanted to know whether it is going to be problematic in any way for me to book this time off? I haven't booked anything yet so these so I could also book for a shorter period. But equally, I haven't booked anything yet and will need to do so soon. 




Is the problem is DataclassEncoder? 

nion swift 


Margret puter

magret margret.buter@amscins.com


Meeting with Jord
-----------------
- He suggested I look at Nionswift
- Eail margret about payslips
- Tell people about holidays. Maurits, Rick etc.






gBQ4SJRzMg7YWmBtBwTH

18/03/2022
==========

Scrum
------
- Its been some weeks and I've finally got around to actually taking measurements with the chipchecking library
- Today I'm at the office and Ben has suggested a demo
- See if I can get the chipchecker library working with a real detector? 
- 


Thinking about how to structure the documentation. Components to consider:
- Report generation. 
- Writing new ProductionChecks
- Running a suite of ProductionChecks
- Proper unit testing
- Serval interface
- Emulator interface. 
- Dataclasses and serialization. 
- Introduction
    - Installation 
- Continueous integration and git workflow. 
- Developers docs





- iphone
- butter
- olive oil
- nice saucepan
- pressure cooker, rice cooker, slow cooker, saucepan
- crock pot
- chicken stock
- Beef
- bay leaves
- fresh thyme
- fresh rosmary




66 GBP for luggge both ways. 33 each


Need to look at crunch account. Send the email. 
Health insurance
Look at holidays for April
Book sardinia trip
Book travel from olbia to cagliari
Email somebody about payment. Margret? 

Hello Margret, I've been told that you were the person to contact regarding questions about pay etc. When I started writing I only had questions about pay but it grew to encompass a couple of other questions. Therefore, if you can't help me with some of these, would you kindly forward this email to the right place? So here we go: 

Last month I was paid around the third friday in the month. I was paid exactly 1500 euros and I am unusure exactly what for (i.e. is it a week, two weeks, week and a half? How much tax did I pay?). I was looking in felixx for my payslips to hopefully answer such questions but I have been unable to locate the payslip under where it should be. Do you have access to it? 

Since I was paid the third weekend last month, I was expecting to also be paid third weekend this month. However I have not been. Could you tell me, which day of the month do we usually get paid? 

Next, I am now an official resident of Amsterdam (yay!). Here is my BSN number: 365160532.

Since I have my BSN I'd like enquire about 30% ruling. Could you tell me what need to be done in order to get this set up? Perhaps its done via the employer? Or maybe I need to do something myself? 

I also need to apply for health insurance. I've been told that this is often this is done with the employer, although I haven't had a conversation with anyone at ASI about this yet. Could you tell me, do we have a means to get health insurance via the employer? If not would it be possible to get some help navigating the murky waters of dutch health insurance? This system is very new to me and I want to make some informed dicisions. 

Thanks
Ciaran 

Health insurence

BNS 

21/03/2022
=============


Monday Morning meeting
----------------------
- Chipchecking library is essentially ready for developing the hardware checks. 
    - Ready and working with the emulators. 
    - Needs testing on real devices
- Me and Ben have planned to sit down together this week work out the details of the hardware checks that will be automated.  

Controversal question - does it have to be ubuntu? Windows mac? 


Contact piu 
Do some code problems.






D:\NionswiftProjects\niondata;D:\NionswiftProjects\nionswift;D:\NionswiftProjects\nionswift-instrumentation-kit;D:\NionswiftProjects\nionswift-usim;D:\NionswiftProjects\nionui;D:\NionswiftProjects\nionui-tool;D:\NionswiftProjects\nionutils


Susan Landlady
===============
- Thinking about getting a TV and a chair/sofa. 
- Curtains/blinds for the kitchen. 
- Cover for the wall by the hob. 
- Bathroom smell
- Water pressure. 




Dear crunch, I intend to close shop at the end of the tax year. Could you guide me on what needs to be done? Thanks





Lido finance
    - change luna for staked luna. 50% only
    - either: 
        - Astroport for 20% total APR
Stader is an alternative liquid staking protocol for luna. You trade 50% of your Luna for lunax
    - Loop markets will take LUNAx. 


    - stSol? Francium as higher yields with stSol than Sol. Use it. 
        - Trade sol for stSol, then pop the stSol into Francium. 


Luna strategies
================

You need luna in terra station wallet for these strategies. 

Stader and loop markets combo: LUNA - LUNAx
--------------------------------------------
- Use Stader to trade 50% of your LUNA to LUNAx. 
    - LUNAx by itself gives you 7.87% APY. 
- Then use Loop markets to add liquidity to the pool for another 15.22%. 
- So its 15.22 + (7.87/2). Total around 18% APY. 


Loop Markets: LUNA - UST pool
------------------------------
- Use whichever tool for and trade 50% of luna for UST. 
- Use Loop markets to provide liquidity for the LUNA UST pool
- 41.96% APY

LIDO finance and astroport combo. stLUNA - LUNA
------------------------------------------------
- Change 50% of your luna for stLUNA using LIDO finance. 7% APY on this 50% of luna. 
- Then provide liquidity to stLUNA-LUNA pool for another 23.78% APY. Total of 23.78 + 3.5 = ~27% APY
- LUNA-UST pool on astroport 31.67% APY

Anchor
------
- Stake UST, which is just USD for 20%. Low risk. 
- Can also borrow against the LUNA and stake more for more rewards. 


Solana Strategies
=================

Francium
---------
- Francium pools look appealing. 
- Use stSOL with USDT to get 99% APY. This involves borrowing so only do this with a small amount of money. 

Lido
-----
- Convert 50% sol to stSOL. 6% APY
- Then stake on francium. 12.33% APY 
- 12.33% + 3 = 15%



maranade finance
-----------------




==========  ============
19-4-2022   29-4-2022
=========    =========


22/03/2022
==========





Scrum
-----
- I spent some time looking at nionswift. 
- They have a multiproject structure
- C++ layer is a launchtool, though I'm not really clear what that means or why its needed, given that the rest of the code is python (as far as I can tell).
- Some of the tests pass some fail. Its not clear whether this is just a result of my environment. 
- I spent some time trying to get some of the tests to pass
    - Error with calling super() on a constructor that directly inherited from Object. 
- I spent some time trying to compile the C++ LaunchTool.
- I also spent some time learning (via the university of youtube) about how light photography works. This is a precursor to understanding the tech behind your detectors. 
- 












    Dear all, while I thank you for looking into this, you have switched internet provider without my permission. Clearly there was something wrong with Ziggi and we had to switch to KPN, but the problem is that I have not had a chance to look at what is on offer before you signed me up to a package. Looking at the KPN website it seems there is a 6 month discount - has this been applied? You've also signed me up for TV, which I do not want (because I can't speak Dutch). Moreover, the prices with KPN indicate that the 200 Mbit/s internet is the best value (42.50 EUR vs 50 EUR after 6 months and 35 EUR for both before then). 

    You should have kept me in the loop before making this decision. Can we retract this application so that I can start again and make an informed decision. 

    With thanks
    Ciaran 



P.S. this is the package I want:




Group dataclasses together in the docs. 


Libertan Libertain. 


setup.cfg


Nionswift slite page: https://amscins.slite.com/app/docs/ntgNls1uE6VSJS


Look into nionswift. Look into the scan acquision part of the nionswift code 
Talk to rick about this. 





----------------------
- Chipchecking library is essentially ready for developing the hardware checks. 
    - Ready and working with the emulators. 
    - Needs testing on real devices
- Me and Ben have planned to sit down together this week work out the details of the hardware checks that will be automated.  


Holiday dates: 
    - between 

19-4-2022 and 29-4-2022
16th April until 1st May


- Basically ready for developing specific hardware checks. 
- Currently writing documentation
- Could do with testing on a real detector. 


Coverage
---------
-  




1750 km


16.11 km per L

A car can hold 50 L of fuel. 

10 L per 100 km

1 / 10 = x / 1750

1750* 10/100


175L 

meaning we'll have to fill up between 3 and 4 times. Assume 4. 


    2.22 EUR * 175 = 400



Things to do
------------

- Set up direct debit for rent
- Get internet - y
- Look at all of my subscriptions on all bank accounts. Prune. 
    - Get control of my spending. 
- Take pictures for Thom.
- Email crunch about closing shop. - y
    - Look at accounting picture. 
    - Figure out what to do with Biosoftware development money / tax funds. 
- Book travel arrangements for Croatia. 
-   get bank account
- Health insurance
- Look into therapy. 

Scrum
-----
- Nionswift. 
- Documentation. Pruning. Cleaning. Making some things that did not makes sense, make sense. 





75% crypto, 25% vanguard. 

Crypto

50% bitcoin
25% luna
25% Sol


Questions
=========
- What is a transister
    - Physics of a transistor
    - energy flow through transistor
    - using models
- What is a semiconductor
- trasistor theory
    - depletion zone 
    - biasing
- transistor can act as a switch


24/03/2022
===========

- Serval PR for robustness with DACs settings
- Yesterday I merged some changes into the chipchecking library. 
- Incremented the version today
- Keep documenting
- Had a long conversation with Siamack about FPGA programming. Much of it went over my head, but it was good to hear it, even if I didn't fully understand it. 



- reports
- Serialisation / dataclasses
- public API
- developers API


creat amsterdam visit chat whats app


Contact pui. Build ubuntu 20 on z590 machines. 




I want to docs to: 
    - first run the doctests
    - This generate a report and coverage. 
    - include this information in documentation. 

    - Then only on the main branch : 
        - then push back to git in a new commit. 
        - do this only when on the main branch for every commit.




        >>> from os.path import join, dirname
        >>> from os import getcwd
        >>> import requests
        >>> from chipchecker import LocalTemperatureCheck, Mpx3Emulator, ChipChecker
        >>>
        >>> # create directory for checks
        >>> root = join(getcwd(), "ProductionChecks")
        >>>
        >>> # try to connect serval to a real detector. Fall back on Mpx3Emulator.
        >>> emulator = None
        >>> try:
        ...     serval = Serval(timeout=5)
        ... except requests.ConnectTimeout:
        ...     emulator = Mpx3Emulator()
        ...     serval = Serval(timeout=5)
        >>>
        >>> cc = ChipChecker(root, [LocalTemperatureCheck], serval_instance=serval, overwrite=True)
        >>> cc.run()
        >>> # when running with emulator, we should stop it
        >>> if emulator:
        ...     emulator.end()
        >>> # stop Serval
        >>> serval.end()
        >>>

        



buy loop. 








25/03/2022
===========


Scrum
-----

- We got equalization working with the chipchecker library. 
- I'm working on documentation
- I can't do much more without guidance on what Benamino wants. 



- Run tests with Tpx3






- deleted dividens for 7200 GBP ish



- 









Things to do
------------

- Set up direct debit for rent
- Get internet - y
- Look at all of my subscriptions on all bank accounts. Prune. 
    - Get control of my spending. 
- Book travel arrangements for Croatia. 
-   get bank account
- Health insurance
- Look into therapy. 
- I would like to learn to be a crypto dev
- Crypto taxes
- Sign up to dutch bank account
- send all money I can to UST
- Hire a little van
    - Go and get my shit from the UK
- pay amsterdam tax bill


Done
---------
- Crunch
    - Email crunch about closing shop. - y
    - Look at accounting picture. 
    - Figure out what to do with Biosoftware development money / tax funds. 
    - crunch reconsiliation
- Take pictures for Thom.
- Okay, so I've been through my crunch transactions and emailed them. 




- nN7s1TpMtmjbTTH1


- 2FkXjNnJdJKxJ6tH




OSMO - UST combo for high yield on osmosis platform




You can use synthetics to pay less gas fees on eth and btc!


track device
figure out local password






First copy is 
- In call to "RoadRunnerImpl(const RoadRunnerImpl &rri)"
    - we do not have a 


- Ultimately this problem emerged because save state is under tested
- during copy, need to also copy compiledModuleBinaryStream

in MCJit, compiledModuleBinaryStream stores the compiled LLVMModule to a llvm stream like object. 

MCJit::writeObjectToBinaryStream() is responsible for creating the compiledModuleBinaryStream.

The compiledModuleBinaryStream is used to create the stringstream. I remember trying to serialize the compiledModuleBinaryStream instead of the string and giving up, though exactly why I can't remember. 


The whole point of serialization is that we do not want to recompile the models. Therefore we do not want to serialize MCJit. However, we do want the binary stream. But once the model is compiled, we discard the MCJit. We can save state once. 


I'm confused. So load state is called by createModel???


size 4891 capacity 8735


WV70WHU


28/03/2022
============

- Chipchecker library is working with the real detector for equalization. 
- Fully documented, though still only a first crack at it. 
- We plan a full day on Wednesday where we work together to get the content of these checks in place.  


Spend a bit more time 


do it in a decorator

today
-------
- Leetcode problems
    - Prefix/suffix trees
- some particle physics course
- Some blockchain course 
- 


Proposal
----------
- I want to spend a small amount of time on programming challenges. 
- I want us all to try out a problem, come up with different solutions
- I want us to share these solutions and talk about the pro's/con's of each. 
- Make us all better programmers. 
- Interview type questions. 



{h49>YxA6T



29/03/2022
============
- Yesterday i did background research. 
    - how does a regular camera work
- Did some background reading and worked more on the documentation for chipchecking library









ideas for use of blockchain technology
======================================
- decentralised funding for scientific research projects
- Professor C -- name. 
- Can I set up the purchase of crypto myself?   
    - Pay 100 EUR for the equiv amount of LUNA, for example. 







Not focusing well enough on people when they speak 
1) Lack of focus. 
2) Slower processing times for communicating with people. 
3) Affects the quality of my response. 
4) Leads to avoidance of communication with people and anxiety
5) anxiety leads to further avoidance behaviours. 
6) Leads to isolation
7) leads to depression


I don't have questions because I haven't focused on what you said. 





Should create a document not a list of DocElements. 







Chipchecker
- Writing documentation. As I do I spot little things that need doing and do them. 
    - crossing t's dotting i's and documenting. 
- Full day tomorrow with Ben and Eric. 


round table
-------------
- I want to spend an hour or so a week on programming challenges so that I'm contineously learning. 
- Its a little academic and doesn't directly help with any particular project, but over time it will boost everybodies 


Tpx3 analysis part of accos
- A windows installer for accos. 


equalization for Mpx3

Tpx3 equalization window for accos. 

look into eut coin


Option 1: dormant state. 
------------------------
- I want to put some money into a high interest savings account. Is this allowed? 
- When is corporatino tax due 
    - 9 months and 1 day after end of year accounting period 
    - 1st September is my due date. So I could keep my company dormant until then and put all money into Anchor for the 20% gain. 


    rcV9$GPxHChS&

The work i am doing right now is computationally very boring. I used to build simulators, and python extensions. 

Wouldn't it be cool to have a DSL for interacting with serval.



30/03/2022
==========

Tricky bug
----------
- Helped Eric pass the tests for his equalisation. 
- Github/bitbucket is not meant for storing binaries. 
- if store a binary to github/bitbucket and then 

- Started looking into building a windows installer. 
    - Pyinstaller is an option. At first it looked like a single command would do the trick so I gave it a shot but this did not work. 
    - Then I noticed that the work for a windows installer has already began, so I will take a closer look at this and pick up from where original developer left off. 
- Today I'll be working with Eric and Benamino creating chipchecker tests. 
- 















kadana 
    - is a layer 1. Not built on Solana. My mistake. 
    - Could be a miner. That would be excellant. 
kadax 
mine kadana!
algorand
gala
Play to earn game: 
    DeFi kingdom 1000% APR! You have to play to game to get Jewel. 

harmony 300%'s 


diesel : 2.149 per liter

Fuel tank: 75 lL

2.149*75 = 161.175 EUR per tank. 

how many km can a liter do? 
    8 to 12 km 

75L * 8km/L = 600 km total  
75L * 12km/L = 900 km total






30 EUR for 100km 
extra 10 EUR for another 100km per day

30 EUR / 100km  = 0.3 EUR for km
10 EUR / 100km  = 0.1 EUR for km

0.29 EUR per extra km over 100km

Crypto
========


ways to use borrowing to earn
------------------------------
- You can use Luna or Sol as collateral to borrow UST an then buy more Luna or Sol. 
- I could borrow against Luna or sol for UST and add the ust to my anchor ust. 
- Where can I make my aUST work for me? 

- aUST
    - Mirror to long/short and earn rewards in MIR
    - delta neutral strategy on youtube 
- Edge protocol to borrow against aUST
- Yield farming aUST with ANC or LUNA
- Loop Markets

Loop markets
----------------
- aUST - Luna = 27.35%. 
- bLUNA - LUNA = 4.3
- bLUNA - UST = 32.46%
- LOOP - aUST = 62.7


Idea: Wrap BTC and put in a pool? 
- wBTC - UST = 35.86%.  
    - So wrap my BTC and double it up with UST


Where is my UST better off, in anchor earning 19.45% or take 8K'
- No, if you put BTC in a pool and its price increases, we risk impearmenent loss. On BTC, this risk is unacceptable. 


Another idea, create a synthetic BTC on LUNA and see if I can use the resulting coin for better than 5% yield.
    - On SOL you can create renBTC on synthetify. 
    - Or is it called xBTC. 
    - You can borrow against mSOL and maybe stSOL, for which I have lots of. 
    - mSOL - whETH on RCA
    - whETH/SOL - 20%
    - BTC / ORCA 49%
    - sollet wrapped btc
    - Serum wrapped BTC

- Consider buying the ORCA token for their high yield liquidity pools.  







Where was it agian that I added to a pool with no impernment loss. 






mSol 6% 
5K extra in 20% pool -> 1K

or lose that 1K but get back 90% on 5K sol and 5K UST -> 4500
 so I should trade 5k aUST for USDC


Wrap my eth and send to solana chain


cardano - use minswap

Don't sell, borrow against what I currently own. Start small until I know what's what. 


Okey, so I want to use the francium pool for btc / sol. As per the francium discord channel. Bit first I need to use the wormhole to wrap some btc. 


Stacks for staking BTC???


01/04/2022
===========

Scrum
------
- Continuation of building new checks in chipcheckers library. 


Jord
-----
- We had a productive day Wednesday regarding what needs to happen with checks
- Now I can build start building them
    - Eric was really helpful at getting at the information in bens head for the software. 
    - This will standardize the quality control aspects of chip checking before sending to customers

- Honestly, its not the most technically exciting project. This isn't a complaint or anything like that, I understand that this is how it goes sometimes. But I used to build C++ libraries, python extension modules and simulators. Now I'm writing a little Python library. 

    - I'm worried that I'll lose my C++ skills which were hard won. 

- Its not technically the most exciting project, but I fully expect things to become more exciting with time. 
    - If after 6 months I still feel this way, I will consider moving on. 
- Technically exciting is learning something that I do not already know. 

- remote powering on. 







- Dimitry
    - Libertain github 
        - framework for processing TEM data. Make by two software engineers who work at <> research engineer. 







Crypto
-------

pool ANC - UST for 48% ish. Not bad. 
    ANC price when entered the pool.    
        - 2.59 UST
        - 1000 UST 
    remove from pool if ANC gets to 3.5













04/04/2022
=============

Morning meeting
- Last week we came up with a plan for some checks that we can automate and we've been implementing those. 
- Last week we came up with a list of checks to implement and we are currently working through them. 


- What am I doing today? 
    - I'm writing some code to abstract the idea of a "ServalTask" so we have a neat framework for things like DacsScans or Equalizatino. 
    - Finish implementing DacsScan. 

- I don't want users to have to call 3 or 4 different methods from the Serval class in order to be able to do a dacs scan and equalization. It should just be one method call a piece. 

Implementing chipchecker methods. 


I'm not feeling 100% 


Hi Jord, I didn't want to mention publically, but I'm not feeling 100% today, do you mind if I don't come to the meeting this afternoon with the guest? 


Hi Jord, just to let you know, I didn't come in this morning as I'm not feeling 100%. I'm hoping I'll be alright in a few hours for this afternoon's meeting but if not I'll drop you a line.



DACs threshold is a list that needs converting to a 


I need to write down what I'm doing. 

- Implement a ServalTask structure to encapsulate serval serval commands
- Implement a DacsTask
    - Build the GET request for each dacs setting
        - Complication - threshold is a list. 
        - Looks like I have dacs scan completed. 
    - Find a way to collect the data locally. 


Hi Rick, I had planned on coming in this afternoon to join your meeting but I'm feeling a little off today, can you manage without me? Its nothing serious, just a littleheadache/nausia but I'd rather avoid coming in, 

Cheers,
Ciaran




Hi Rick, I was hoping to make it in this afternoon to join in your meeting but I'm feeling a little off. Can you manage without me? 

Thanks
Ciaran


Headache is getting worse so I'd like to stay home today - can you manage the meeting without me? 



    def _plot(self):
        for chip_id, dac_dct in self.dacs_data.items():
            fig = plt.figure()
            sns.despine(fig=fig, top=True, right=True)
            for dac_name, dac_series in dac_dct.items():
                print(dac_name, dac_series)
                plt.scatter(dac_series.index, dac_series.values, label=dac_name)
                plt.xlabel("Scan Value")
                plt.ylabel(dac_name)
        plt.show()


- for now the plot is hard to see. 
- but soon i will implement the html writer and see what we can do with knteractive plots
- 



Round 1: 
-----------

- deposited 6500 UST to planetfinance as supplier. 1300 USD is      +20.0%   
- borrow 75% (3,748) UST from planetfinance.  APY pay 812.5 USD           -12.5%
- 3740 deposited into anchor for 748 USD                            +20.0%
- 2805 borrow                                   


Loop markets
---------------
When entering pools.
- Loop price: $0.09188
- Eth price: $3,513.12
- Anchor price: $2.66
- LUNA price: 115.53

Exit the pools on 11/04/2022









05/04/2022
============

Scrum
------
- I implemented a structure for handling larger tasks, like equalization or dacs scan. 
- I implemented Dacs scan. 



Things to do
--------------
- Sort out bills
    - DigiD requested. THis is needed for paying amsterdam tax bill
    - pay amsterdam council tax
    - gas/electric
- bank account. 


gas: 6972 m2
electric: 9843 kwh


    
gas: 6972 - 6868 = 104 m2 
electric:  9843 - 9733 = 110 kmh



06/04/2022
============

Scrum
------
- Continued building chipchecker checks
- Want to access the raw data inside Serval output. 
    - At Rick's suggestion, I was able to read the raw data directly from the .tiff, though I have no way of knowing whether the data is what I should be looking at. 
    - Been trying to put them together into a video. Should be possible but current attempts result in corrupt videos (mp4 and avi). 
        - Is not the priority for right now. 
    - Chipchecker meeting today. 



Chipchecker Meeting
====================

Progress from between 30-03-2022 and 06-04-2022
-------------------------------------------------

- PowerUpCheck. 
- IDCheck
- BaselineTemperatureCheck
- ServalTask: A framework for executing a collection of serval commands
    - DacsScanTask, handles the dacs scan itself. 
    - We should do the same with equalization. I started this, but stopped again. Prioritize. And maybe Eric would prefer to do this? 
    - Checking temperature could also be done this way. 
    - Advantages: 
        - More organised. Better testability. And, it will be possible to do use ServalTasks outside the context of chipchecking (when/if we repurpose this tool).
            - i.e. you can just do a dacs scan. 
- DacsScanCheck. Uses the DacsScanTask, via Serval.dacs_scan() method. Adds checks. 
- StressedTemperatureCheck
- BackgroundImageCheck. 

- I've been implementing the data collection, but not the checks. We need to discuss the checks for each task. 





Loop this:
- Deposit UST to get aUST https://app.anchorprotocol.com/earn
- Bridge aUST back to your BSC wallet: https://portalbridge.com/#/transfer
- Supply aUST on Green Planet https://planetfinance.io/lending
- Borrow UST on Green Planet https://planetfinance.io/lending
- Bridge UST to Terra https://bridge.terra.money/


supplied = $7139.98
borrowed = 3,851.23



10k -> +20%
7200 : -7.16^

net on 7200 is 12.84%
net on 10000 is 20%         20% of 2000 + 20% of 7200 
                                2000 + 1440
                                = 3440
                                What percentave of 17200 is 3440? 

suppliedAmount * supplyApyAsDecimal - borrowedAmount * borrowApyAsDecimal

17200*0.2  - 7200*0.0716
3440-515 = 2925
2925 / 10000 * 100 = 29.25

Convert all supplied and borrowed asset amounts to a single asset (like USD or ETH).
Calculate the sum of (suppliedAmount * supplyApyAsDecimal - borrowedAmount * borrowApyAsDecimal) for all underlying assets.
If the calculated sum from the previous step is >0 then Net APY = 100 * (sum / totalSuppliedValue). If the calculation from the previous step is <0 then Net APY = 100 * (sum / totalBorrowedValue). If the calculation from the previous step is 0 then Net APY = 0.



7200 / 10000 = x / 20 


7200 / 12.84 = 

how to work out net APY? 
    make 10K proportionally smaller

    10000/7200*20



email sysbiouw@gmail.com 
password SyS-BiO123




07/04/2022
==========

Scrum
-----
- Yesterday we had a long discussion about chipchecker contents
- We added detail and finished first draft of what the medipix checking procedure should look like. 
- Also implemented a few of the suggestions. 

- Today I come into the office and have a meeting with Thorbjorn at 2pm. 


- Propogate config files from equlailzation through to image collection. 


Save the dacs / pixel config files to root directory. 
Location should be configurable. 


Need to be able to pass arguments to ProductionChecks. 
Therefore it should be tuples. 


take_integrated_measurement(). 

MeasurementTask
IntegratedMeasurementTask

takes a DetectorConfig and a Destination object. 

serval.measurement_contineous()
serval.measurement_sequential(bit_depth=12 or 24)
serval.




UST in metamast : 11121.977303252
UST in terra: 1,091.802636


26000 * 20% = + 5200 
12765 * 20% = + 2553
16546 * 12% = - 1985



08/04/2022
=============

Scrum
-------
- Yesterday I made some adjustments to tasks I already completed. Lots of little things which together add up to a big thing.  
- Made progress with BackgroundImage collection
    - Needs to use output from equalization
    - low and high gain modes
        - three image acquisitions one per mode. 
- Today is about pixel masking. 
    - I need some example images that I can use in tests. 
    - The example images should contain a broad spectrum of situations. 
    - Could also just randomize this, since its just a matrix. 

- Rick, do you have any go-to algorithms or techniques for handling pixel data? Do you just linearly traverse the array? 
- Sparse matrix? 



Chip coordinates to image coordinates. 
YOu have an image, you know which is noisy and you want to convert from image to chip coordinates. 

Deteector layout. 


                         'DetectorOrientation': 'UP',

                         - UP means image is not rotated. 
                         - Can also be Right, Left or Down. 
                            - Look at the mpx3 manua. 
                        - Can also be mirrored. 


              'Layout': [{'Orientation': 'LtRBtT', 'X': 0, 'Y': 0},
                         {'Orientation': 'LtRBtT', 'X': 1, 'Y': 0},
                         {'Orientation': 'RtLTtB', 'X': 1, 'Y': 1},
                         {'Orientation': 'RtLTtB', 'X': 0, 'Y': 1}]},


9890.45




11/04/2022
============

D:\AmsterdamScientificInstruments\ccplaygarden\chipchecker\production_checks\_background_image_check.py:132 DEBUG: Collecting data with detector config: 
 {
  "LogLevel": 1,
  "Fan1PWM": 100,
  "Fan2PWM": 100,
  "BiasVoltage": 100,
  "BiasEnabled": false,
  "Polarity": "Positive",
  "ChainMode": "None",
  "TriggerIn": 0,
  "TriggerOut": 0,
  "TriggerPeriod": 1,
  "ExposureTime": 1,
  "TriggerMode": "CONTINUOUS",
  "nTriggers": 10,
  "BothCounters": false,
  "Colour": false,
  "ChargeSumming": false,
  "GainMode": "SLGM",
  "PixelDepth": 12,
  "IDelayConfig": [
    15,
    15,
    15,
    10
  ],
  "DetectorOrientation": "UP",
  "type": "DetectorConfig"
} 
 and destination: 
{
  "Image": [
    {
      "Base": "file:///D:/AmsterdamScientificInstruments/ccplaygarden/chipchecker_test/checker_tests/BackgroundImageCheck/BackgroundImageCollectionCheck",
      "FilePattern": "frameintegrated%Y-M-d-H-m-s",
      "Format": "tiff",
      "Mode": "count",
      "IntegrationSize": -1,
      "IntegrationMode": "sum",
      "StopMeasurementOnDiskLimit": false,
      "QueueSize": 16,
      "Thresholds": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7
      ],
      "Corrections": [],
      "type": "OutputChannel"
    }
  ],
  "type": "Destination"
}







Things to do
=============
- mask multiple pixels at once via serval . 

- Flipping or rotating the camera/chips does not change the coordinates that need to be masked. 


- The first index, chip 0 is X: 1, Y: 0. So this is the bottom right. 
- The chip reads right 0 to left 255 and bottom to top 0 to 255
- In this case the bott


- We want top left to be chip 0, row 0 col 0. 


- I ws getting a littl confused with indices. 
- 0, 1 is top left. 


12/04/2022
==========

- Today has been about understanding the data layout of chips and orientations. There is a difference between the chip coordinate which starts at the bottom left and chip index which is the index in the list of chips. 

- It took a while to distill the issue into a exact problem. 
- From this I was able to design a set of tests to pass TDD style. 


- I'm thinking either: 
    - Big if else statement that converts "screen pixel coordinates" to chip coordinates


Questions

- pixel masking one pixel at a time. 
- Rotation and flipping does in serval does not rotate masking. 
- 10 bits, which 
    - in the manual. 
    - either the first or last. 

I have a couple of ideas knocking around on how to structure this but I'll reserve telling you for now because they are partially formed. 

- What about the idea of a mapping coordinate system.




class CoordinateMapping. 

class ScreenPixelCoordinate
class ChipCoordinate

Inherit from one of the 
class ScreenImage. 
class UpImage
class UpMirroredImage







Rick - could you point me to the part of serval code that deals with computation of BPC index from (chip,row,col)



First inverse. Then 

f = From mirror to non-mirror. 
g = From rotated to unrotated


f(g(x))





You can use firmware argument to emulators to switch modes. 


- The framework of the chipchecker library needs to be expanded slightly, from an OOP perspective, to capture of a result


There are some ideas that I'm thinking about in terms of OOP design. It'll take a little more time. 


Beginings of a design expansion 

Image derived from open cv or Pilow. 

Coordinates abstraction and mapping algorithm.



Could you clarify. I've read on gov website that friday is a bank holiday and my dyson (partners company are off Friday). 

Is Friday a public holiday? 


Rent a largish car

13/04/2022
==========
- I won't go into too much detail but I'm distilling flip and rotate operations into single equation so that we do not need to rotate an entire matrix just to mask a single point. 
- Class system where the base is a NPoint, where the point is N dimensional space. 
    - ViewPoint is a point in ViewSpace

- Concepts of Point and Space. 
    - ViewSpace
    - PixelSpace
    - ChipSpace

- Today, I want benamino to just get cracking with tryout out the library on his own. 

10001011000


Okay here's what happened. I came home last night and worked instead of giving you attention. You were annoyed at this but let it go. However, you sort of didn't let it go because your anger is being expressed in a kind of passive aggressive nit picking. You might not even realise that it was happening.

Basically you're being resentful towards me and I can feel it. 

Then you stormed out!



14/04/2022
==========
- I figured out how to get pixel masking to work by manipulating the BPC in memory. 
- Now make it pretty 


- In mathematics, we use Cartesian coordinates, X, Y positions where X increases and decreases horizontally and Y increases/decreases vertically. 
- In mathematics we can go in the negative direction, but in programming our indexes are strictly positive. 
- In mathematics we always use (x,y), the x selects the column and the y selects the row. In programming, we use (y,x) to select the row first then the column. 


is 180 rotation the same as flip? 

15/04/2022
============

Scrum
------
- I know how to manipulate the BPC data
- As part of this, we need to translate screen coordinates into chip coordinates. I also know how to do this.
- So I'm building a little tool for handling the coordinate conversion before returning to the BPC. 
- Hopefully I'll get this done today, but its probably a little more than 1 days work, counting tests and docs etc.




class MirrorType(enum.Enum):
    NORMAL: str = enum.auto()
    UPSIDE_DOWN: str = enum.auto()
    BACK_TO_FRONT: str = enum.auto()


class OriginType(enum.Enum):
    TOP_LEFT: str = enum.auto()
    TOP_RIGHT: str = enum.auto()
    BOTTOM_LEFT: str = enum.auto()
    BOTTOM_RIGHT: str = enum.auto()

class OriginUpdateTypeRotation(enum.Enum):
    """Find current origin label. 
    
    The next label is the new label
    when you rotate right, the last label is the label used to update 
    when rotate left. 
    """

class OrderType(enum.Enum):
    ROW: str = enum.auto()
    COL: str = enum.auto()




Step 4: Deposit UST to get aUST
Step 5: Bridge aUST back to your BSC wallet
Step 1: Supply aUST on Green Planet
Step 2: Borrow UST on Green Planet
Step 3: Bridge UST to Terra


withdraw aUST on green plannet
deposit ust on green plannet


Use portal to move ust to BSC








262.757247

3,311.473597


terra bridge: 0x3d4350cD54aeF9f9b2C29435e0fa809957B3F30a
              

notes
======
- rotation in polar coordinates is easy. 
- conversion between cartesian and polar coordinates is easy
- But it uses trig functions. Are these expensive compared to simply using cartesian space? 
- 

- could represent an image as a np meshgrid 
    - has both types of indexing which is cool
- or an mgrid which is a multidimensional mgrid


02/05/2022
==========
- I've been around Europe in a van
- Netherlands -> Germany -> Austria -> Slovenia -> Croatia -> Italy -> Switzerland -> France -> Luxembourg -> Belgium -> Netherlands


Monday morning meeting
----------------------
- I'm not sure whether there has been any progress with chipchecker whilst I've been away but I'm back now and will get back to automating noisy pixel masking.
- The essence of this is done, but I need help navigating serval

Scrum
-----
- Good chance to stand back a little
- First job is to remember what I was doing before I went away. 
- I think I had a problem solved but needed some help with Serval. 





How is accos being tested? 


option 1 - grey out record/preview button


Use the tooltip to give information

Question - how is all this being automated tewting 


Full
Not writable
Not readable? 



Work for issues
-----------------
- Dropped frames window should be red if certain conditions are met. I.e. integration mode on and frame rate is high aka over 500 frames per second. 
- We also want a warning at the status bar at the bottom of the screen.  
- pop up. 


&5XiH58atPD$gStgeosb^4ZwwY$$cbf&o*n9GGaU9bJcoUu8t5i6J!bwVx4*QSrN


A problem. 

Accos uses a symlink on linux to make the timepix3-analysis-toolkit/tpx3_analysis folder look like a folder called tpx3_analysis. This is not a cross platform solution. Instead, we could rename timepix3-analysis-toolkit/tpx3_analysis to timepix3-analysis-toolkit/tpx3_converter and then we can use the PYTHONPATH to get a better solution. 


Accos uses a symlink on linux to make the timepix3-analysis-toolkit/tpx3_analysis folder look like a folder called timepix3-analysis-toolkit/tpx3_converter. This is not a cross platform solution. On windows, it is not even possible to copy the timepix3-analysis-toolkit/tpx3_analysis folder manually, to a folder called timepix3-analysis-toolkit/tpx3_converter since the symlink is a file called tpx3_converter (name clash). 

So, I think the most sensible solution I can find is to rename timepix3-analysis-toolkit/tpx3_analysis to timepix3-analysis-toolkit/tpx3_converter and then in Accos we can use the PYTHONPATH to tell Python where to find tpx3_converter


03/05/2022
============

I have a pretty sharp critisism of accos - Where are the tests? 

Things to do
-------------
- Pay amsterdam tax
- health insurance
- dentist
- doctors appointment??
- Get amsterdam house price data, and all that
- Start search for house. 
- Get bank account
- Talk to mortgage people. 
- Talk to hmrc to update tax code
- Talk to crunch, progress? 


Work
-----
- QTest class contains what we need for unit tests in python 
- proposal, after the 1.1.0 release of accos, let me begin writing a unit test library for accos. 
    - Catalogue the features. Begin unit testing. 

- Users can either type in a direcory  or use the pciker. 
- So the checks also need to be performed in rawFolderUpdate

- I'm working on jira issues in 




I need to use the statusBar.onError method. 
But how to access the instantiated statusBar from the LeftPane? 

- Or pass the main window to the left Pane in constructor. This seems wrong.  
- Static method in MainWindow to update the status bar? 
- 



Create a RepeatedTimer. 
Periodically check whether the data directory is valid. 
When it isn't keep checking. 
When it is, stop timing. 

if data folder exists

04/05/2022
===========
- I've been working on the data directory permissions problem. 
- Realised that the os.access method is unreliable on windows, so I will write these functions myself. 
- 

For health insurance:
    - independer.nl




Start at begining

Read only
Write Only 

write permissions = S_IWUSR | S_IWGRP | S_IWOTH
read = S_IRUSR | S_IRGRP | S_IROTH

You cannot CD into a directory when you do not have execute permissions


Complication. You cannot CD or write or do anything in a directory if it does not have execute permissions, even if you have write permissions. 

Therefore, if a data directory does not have execute permissions, we cannot write to it. 


Getting accos to work on wsl2
------------------------------
I had to do some investigative installation to get pyqt5 working on wsl. The problem was a missing dependency of one of the shared libraries used in PyQt5. ldd confirmed that I needed to install `sudo apt install libxcb-xinerama0`



Is a directory readable? Well checking depends on whether you are owner, group or somebody else. 
Further, the executable flag must be set to allowed. 

Is a directory readable? To who? The answer depends on who you are. 

If you are owner of the directory then you need 
    - drwxrwxrwx
    -  ^

Question - does the "everyone" flag trump the owner flag. 

So if a file is "Others" rwx and you are owner, can you still modify the file/directory? 


So now I have two accounts, ciaran and alterego. 
I want alterego to create a file with drwxr------

if d------rwx, can owner still access file like everyone else? 

The command "chmod -o=r testdir/", where o is other and r is read will set d--------- to dr--r--r--. This implies, that setting other to r also sets group and owner


MODE grammar: '[ugoa]*([-+=]([rwxXst]*|[ugo]))+|[-+=][0-7]+'.


how to os.access behave when not all are set to executable. 





We need to execute a command every second if we do not have an appropriate data_directory. 


default rawDataFolder is always ~/data. 
Then it get's changed to whatever was saved. 
So where is it saved and how can I change this more quickly.


main window is being called twice - why?

popup when directory does not exist - this directory does not exist, do you want to create it? Have a checkbox which says do this always and autoset the checkbox to True. 


So, this is a validation. Maybe we should lump this into the validated wiget? 

This is a textbox which contains a path. I want to validate that the path has the correct permissions. This is (maybe should be) the business of the validated widget. 


Behaviours
-----------
1) DataFolder box allows you to enter any path
2) the path may or may not exist
3) If the path does not exist, nothing happens until user presses preview or record
    - When button pressed, we check to see if the create data folder "if not exist: create" box is True. 
    - If it is True, then create the folder and run the experiment. 
    - If it is not True, then pop up and ask the user if they want to create the folder. 
        - The box has a "always allow checkbox" which will check the "if not exist: create" box automatically

2) Nothing happens until user presses preview or record
    - We need to validate that its a valid path


I'd like to write a domain specific language for detector. 


/05/05/2022
============

- In short, I'm making progress with the data folder permissions problem


- I got my linux development environment up and running
    - Problem with Qt on WSL2 - one of the shared libraries dependencies was missing so I had to install it.
    - investigative installation  

- Note: customers who have requested windows support can use this. 

- Wrote tools for determining directory permissions and tests. 
- Begin playing with creation of a checkbox for users to specify whether they want us to create the directory they have chosen.


- Might be possible to use a different metaclass for widgets that we use and want to test. 

    TestableQtWidget

    timer


Directory text is constant beause of


I was trying to use the RepeatedTimer until I realized that this particular timer will not work out of the box because we need different input to the function each time it is repeated. (currently only the first value gets repeated.)

Insted of using the RepeatedTimer, use another thread each time.  



Build a feature hierachy for the software. 

06/05/2022
===========

- Yesterday problems RepeatTimer was constantly using the same arguments because string passing is by value, not reference in Python.
    - Once I understood this it was a simple matter to update the arguments. 

- I only want the data folder line edit to run when we lose focus. How do i do this?

- I want to build my own mini gui app with model-view-controller. Its going to really help me get on board with how things are done in accos. 

- Havent started gui-testing yet

- Finish early today, because I've spent a lot of time on this over the last few days. 



Avax ust lp on beefy finacne .
    - Autocompounding. 38% APY. Gooood. 

Use sAVAX as collateral on anchor. Borrow UST. Then stake UST. 






sparkling water 


I set SBMLOPTIONS_RECOMPILE to true to force a recompile (assuming I built LLJIT to respect this variable).

plot all in order. LLJit model 0 through to x then MCJir 0 through x. 

No averaging. 


LLJit
sbml                                               repeat                    
D:\roadrunner\temp-biomodels\final\BIOMD0000000... 0       0.029918  0.030700
                                                   1       0.020862  0.021687
                                                   2       0.022913  0.023697
                                                   3       0.020498  0.021232
                                                   4       0.021235  0.022075
MCJit
D:\roadrunner\temp-biomodels\final\BIOMD0000000... 0       0.090949  0.091757
                                                   1       0.080610  0.081414
                                                   2       0.089672  0.090426
                                                   3       0.077763  0.078521
                                                   4       0.078367  0.079244

MCJit / LLJit
0.090949 /  0.029918 = 3.03994250953 speed up with LLJit



finishedEditing

editingFinished() - 


self.inputWidget.editingFinished.connect(self.editingFinished)


if folder does not exist and no write access on parent. 


ValidatedWidget for file path / data folder


Throw error with the validated widget


get rid of data folder button. 



no exist and can't create. Same as no read write permissions. Block record button. 


- When the parent directory is not writable then log error message in red text under the line edit widget. 
- If the parent directory is writable but does not exist. User is warned that the folder does not exist and will be created. 
- If is writable, then everything is okay. 
- Use the validated widget validated file. Use the setValidationFn method.     use me for specifiying a validation function. Check data folder. 

- RAise a ValidationError which is handled 




if does not exist and can be created, this is fine as it will be created by serval. But warning to user. 


21st june - Friday 1st july



The validation and the setter parts of the widget are different. 
Frist you validate, then you set. 


need to ValidatedDirectorySelectorWidget.fileEdit to connect to updateRawDataFolder


This is recursive
    - Tim

The timer is not working 



10/05/2022
=============

- I am replacing old UI elements for data folder with a validated widget. 
- I haven't quite got the algorithm working yet. 

---
- I'm not stuck, just in the process of working out how to do it, which will take me longer than you since I have more to learn with this code base. 
- If after the software meeting later I haven't done it, perhaps we have a conversation Maurits. 



Components of the algorithm
------------------------------
- Instantiate a RepeatedTimer which calls the TimerFired method every second. 
- Create the ValidatedDirectorySelectorWidget, which is bound to the rawDataFolder. 
    - Each time the text edit for data folder is changed the "valueChanged" method is called. 
        - submit default to "ON_DID_CHANGE" meaning the valueChanged method updatesModel
            - updateModel(). performs the validate method and then sets the rawDataFolder to new value. 
- The validationFn is called. 
    - I've been playing around with either rawFolderUpdate or dataFolderValidationFn for the validation fn. 
    - Since the rawFolderUpdateFn does the same work that the ValidationWidget.updateModel() does, the main work of this fn is not needed. *however*, this method was starting the timer. So perhaps we should have another method which starts the timer then does the validation? 
- dataFolderValidationFn




Th emodel is updated with the new rawDataFolder, but not with the value of isDataFolderReadyForDA. 
The model.isDataFolderReadyForDA is updated in the LeftPane, but is not being used by the toolbar? 




Unit testing
---------------

- pytest-qt provides us with a pytest fixture, a tool for replacing the usual TestCase subclass with piecewise setup functions. 
- pytestqt captures Qt logging. But we do not use it. So I may have to implement this myself



import os.path
import shutil
import unittest
import pytest
from pytestqt.qtbot import QtBot

from PyQt5.QtTest import QTest
from PyQt5 import QtCore

from accos.util.directory_utils import LinuxPermissionFlags
from accos.view.LeftPane import LeftPane
from accos.model.Model import Model
from accos.constants import ACCOS_DIRECTORY


#######################################################################
# Fixtures
#

@pytest.fixture
def rootDirectory():
    return os.path.dirname(__file__)


@pytest.fixture
def readonlyDirectory(rootDirectory):
    readonly = os.path.join(rootDirectory, "readonly")
    if not os.path.isdir(readonly):
        os.makedirs(readonly)

    # read as: "all but write"
    os.chmod(readonly, LinuxPermissionFlags.ALL ^ LinuxPermissionFlags.WRITE)

    yield readonly
    os.chmod(readonly, LinuxPermissionFlags.ALL)
    if os.path.isdir(readonly):
        shutil.rmtree(readonly)


@pytest.fixture
def writeonlyDirectory(rootDirectory):
    writeonly = os.path.join(rootDirectory, "writeonly")
    if not os.path.isdir(writeonly):
        os.makedirs(writeonly)

    # read as: "all but read"
    os.chmod(writeonly, LinuxPermissionFlags.ALL ^ LinuxPermissionFlags.READ)

    yield writeonly
    os.chmod(writeonly, LinuxPermissionFlags.ALL)
    if os.path.isdir(writeonly):
        shutil.rmtree(writeonly)


@pytest.fixture
def execonlyDirectory(rootDirectory):
    execonly = os.path.join(rootDirectory, "execonly")
    if not os.path.isdir(execonly):
        os.makedirs(execonly)

    # read as: "all but read"
    os.chmod(execonly, LinuxPermissionFlags.ALL ^ LinuxPermissionFlags.EXECUTE)

    yield execonly
    os.chmod(execonly, LinuxPermissionFlags.ALL)
    if os.path.isdir(execonly):
        shutil.rmtree(execonly)


#######################################################################
# Tests
#
def test_create_readonly_directory(qtbot, readonlyDirectory):
    model = Model(ACCOS_DIRECTORY)
    left_pane = LeftPane(model)
    left_pane.dataFolderSelectionWidget.getFileEditWidget().setText(readonlyDirectory)
    qtbot.keyEvent(QTest.Release, left_pane, QtCore.Qt.Key_Tab)
    import time
    time.sleep(5)
    assert left_pane.dataFolderValidationTimer.getCount() == 5


# class DataFolderUnitTests(unittest.TestCase):
#     """Note is it possible to use the canonical style of unit testing with qtbot as well.
#
#     The pros of using TestCase subclass:
#         * Its canonical and what python developers expect.
#         * We have access to assert methods, like assertEqual
#
#     The cons:
#         * Use of the pytest.fixture precludes easy switching between different test frameworks. But then
#           using qtbot locks us into pytest anyway!
#         * No access to assert methods, like assertEqual and we need to instead use regular assert.
#         * pytest developers suggest moving away from TestCase subclass if using fixtures.
#
#     """
#
#     @pytest.fixture(autouse=True)
#     def getQtBot(self, qtbot):
#         """Make qtbot available for other tests in the TestCase
#
#         The fixture is similar to setUp in that it is run before every test method.
#
#         """
#         self._qtbot = qtbot
#
#     def test_x(self):
#         print(self._qtbot)



other use cases
- folder acquires permissions outside of accos 


- Maybe the rawDataFolder variable is not being properly updated? Because when you press record, it uses the direcotry parent? 

Its not aknowledging the new path given. 

monitor the variable for changes. Once it changes, we need to update the ToolBar updateToolBarNotification



It was working all along, but I was using the wrong test folder. 




import os.path
import unittest
import pytest
from PyQt5.QtTest import QTest
from PyQt5.QtWidgets import QApplication
import sys
from accos.view.MainWindow import MainWindow
from accos.model.Model import Model
import accos


ACCOS_PATH = os.path.dirname(accos.__file__)


class DataDirectoryTests(unittest.TestCase):

    @classmethod
    def setUpClass(cls) -> None:
        cls.app = QApplication(sys.argv)
        cls.model = Model(ACCOS_PATH)
        cls.main_window = MainWindow(cls.model)
        # main_window.show()

    @classmethod
    def tearDownClass(cls) -> None:
        cls.main_window.close()
        cls.app.exec()

    def test(self, qbot):
        qbot.addWidget(self.main_window)
        print(self.main_window.close())





if __name__ == "__main__":
    unittest.main()





11/05/2022
=============
- I think I have it working. 
- Data folder is doing what we want. 
- it was actually already working, but I was testing it wrong. 
- Now I focus more on tests. 


- Accept the loss on Half? 


busd???


deprecated needs to go

writonly mode - preview should work. 


        if not os.access(rawDataFolder, os.R_OK):
            self.model.showWarning('I/O error', 'No read access to folder:\n %s' % rawDataFolder)
            self.endResetModel()
            return


No repeating logs for the timed functions.   -- yes
One persistant error message in the status bar  -- no because how to turn off again?
Reload button MeasurementVS -- this should trigger validation for data folder
Grey out buttons incorrect after changing filesystem afte the fact. .
preview only in write only mode.  -- yes
.. remove allowCreateDataDirectoryIfNotExist



The timer haven't been stopped in the readonly to not exist case, which is why the next iteration

only if the model has been changed, does the ui get updated. i.e. the setMV for this variable means that only if the new value is different from the old does the ui get updated?


updating the ui (postUpdateUI) validates the raw data folder and if we try to update the ui in the validation routine we get infinite recursion. 

But, we *do* need to update the system once more after 






in logError, if this msg same as last msg, don't post. 




 
- Remember to remove ssh key folder. 
- The "about" window looks suspect. 
    - Version/commit hash/message. 

- 1GB connection. Both medipix and timepix. 
- scan doesn't finish sometimes, 
- It is possible to scroll samples box whilst scanning. 
- Ambiguous plot colours on dacs. 
- YOu can already toggle on/off
    - Implement a "toggle all" button. 
- Each chip works, that is produces "good looking" graphs. 
- DACS tuning 
    - is working. Target values are reached. 
- Equalization
    - Can't scroll down whilst equaliationi is running. 
    - Pressing the cancel button whilst equalizing results in a threading error. Need to kill thread gracefully. Syncronization problem. 
    - Chip board coordinates are not working correctly in the "excited pixels" window. 
        - Chips are stacked, not respecting the proper layout
    - ONce dacs and equalization finished. Save the files for later use. 
    - Pressing the equalization "Apply" button does not upload the dacs settings. 
        - It seems the actual setting are being applied, but the dacs file location is not saved. 
        - i.e. it does not recognize that the dacs settings are uploaded. 
        - When saving dacs to disc, the dacs file field should up automatically updated. 
    - After equalization, dacs threshold values are very wrong. 
    - Python error when press cancel button (probably), type error with None. Histogram was "None". Do not know why. 

- Flash software - slot 52? Why 52? 
- Always use autotrigger mode for equalization. The popup when in wrong mode requires us to do this manually, but really there is only one mode that makes sense. So why not just set it to autotrigger behind the scenes? 

ThresholdModes = [contineous, 1 threshold, shutter based, 2 thresholds shutter based

For each ThresholdMode: 
    multiple pixel depths. 

Modes
- Contineous mode pxl depth = 1. 250 fps works okay. 500fps works. 
- Contineous mode pxl depth = 6. 500 fps. Dropped frames at the start of DA. 
- Auto trigger (pxl depth 12), 
    - FPS 250, dropped frames. Exposure time 1uS.  

- Messages the understanding the limit of 1 Vs 10 gb mode. 

- Adjust dead times in serval, for 1 bit mode. When FSP 9999 and exposure time 1 uS. 




""" 
The money is already lost. UST either spirals down to 0 or repegs to 1 usd. 
If it spirals down to 0, what is the point of holding. I'm just going to lose the money. 
If it goes back to 1usd, then I loose money on the trades, -30%/-40% and more. Currently 
at -70%. If this happens, then it will not do so in a straight line. It will weave up and 
down back up to its peg. So, I should buy more UST with USDT, sell when it goes up. 

"""    

Spend 100 USDT to buy 250 UST at 0.4 USD. 
Sell  250 UST at 0.6 for 150 USDT
Spend 150 USDT at 0.4 for 375 UST 
Spend 270 USDT at 0.4 for 625 UST  - Total USDT spent is now $420 for 1000 UST. Now sell at 0.6
Current... Open order
Sell 1000 UST at 0.6 for 600 USDT, making $180 profit. 



buy 10 UST with 0.3688 USDT  



If I do nothing and the peg comes back, then my UST balance is restored. Therefore, it is worth keeping UST. However, there is also an opportunity to 




13/05/2015
-------------
- I have a couple of tweaks left to make on my branch and then I'm going to spend more time exploring the code, writing tests etc. 

- Test the notification system. 

4634


0.00025000 886.78777000 USD in



Scalping trading. 
===================

Rules
- You can only take long position when the 20 is above the 50 which is also above the 100 MA line
    - long --> 20 > 50 > 100
- You can only take short position when the 20 is below the 50 which is also below the 100 MA line. 
    - short --> 100 > 50 > 20
- To buy back into a position, wait until:
    1)  the red bar crosses the 20 MA line. 
        - Use the 50MA as stop loss, unless:
        - if the price pulls above the 50 MA, then we use the 100 MA as stop loss. 
        - Target 1.5 risk / reward ratio
    2)  The william fractal is on the red bar pointing upwards (green). 
    - This is entry signal. 
- Rule: If you see a price close below the 100 MA, you cannot take the next entry signal. 



For sell orders, we recommend:
Limit price > current market price > stop-loss trigger price (stop-limit)
For buy orders, we recommend:
Limit price < current market price < stop-loss trigger price (stop-limit)
*We recommend setting the limit price closer to the stop-loss trigger price.



16/05/2022
================
- Monday morning meeting + scrum. 
- Friday I spend time trying to use some of the objects in Accos. 
- The aim was to understand better how they work so that I can test their behaviour. 
- Started with the notification system

Problem: Cannot update grey button
-----------------------------------
- __getattr__/__setattr__  used in accos.Model to:
    1) set `Model` values
    2) validate user input 
    3) update UI, via notification that values have been changed. 
- I am used a RepeatedTimer to repeatedly check that a data folder provided is valid. 
    - When invalid, the RepeatedTimer checks for validity of current data folder every 1 second. 
    - Mecanically, this is achieved with a boolean variable `isDetectorReadyForDA`. This becomes `False` when `rawDataFolder` is invalid.
    - When the data folder becomes valid again, the RepeatedTimer is stopped. 
    - *Problem*, once the timer is stopped, despite the value of the variable being changed *and* going through the validation system, the new value (True) is not propogated through to the toolBar. 


class ClearErrorNotification

persistent messages are really a part of the status bar, not the logging system? 

- turn off RepeatedTimer in finalize method.


EndAllTimers notification???

Persistent flag will
    1) Make the StatusBar error message stick. 
    2) Make the log stop logging. 


    
# def _log(colour, header, *msg: Any, persistent: bool = False):
#     """Log a message
# 
#     Args:
#         colour:     a colour code
#         header:     label for this log, such as [DEBUG]
#         *msg:       the message to be logged. Variadic arguments are unpacked
#                     (much like `print("first", "second")` )
#         persistent: When False, the current message is logged to the
#                     StatusBar for a limited amount of time (10 second). Otherwise
#                     the message is persistent.
#     """
#     global _hasBeenLogged
#     print("persistent", persistent)
#     print("_hasBeenLogged", _hasBeenLogged)
#     if persistent and _hasBeenLogged:
#         incrementLogId()
#         # print("getLogId()", getLogId())
#         return getLogId()
# 
#     # print("after persistence")
#     msg = ' '.join([str(i) for i in msg])
#     _handleMessage(0, colour, header, msg)
#     if persistent:
#         _hasBeenLogged = True


If Terra 2.0 does not have UST, and UST holders pre-crash get airdropped 25%, is it in our interest to sell UST for as much as possible right now? 




There is a nuance regarding the word "not nice". Is there a dutch phrase commonly used that directly translates to "not nice" in english? The reason I ask, is because I have noticed many people use the term "not nice". While I understand their meaning, I think as a native english speaker I interpret this differently to the Dutch. I see "not nice" as kind of nasty, there is an implied "nastiness" towards an individiual. When you are nice to somebody, it is a human to human interaction. Or even human to animal. But being nice to a machine doesn't really make sense. Or not nice for that matter. 



If read and execute OR full control. 


Need to download new spidr and serval artefacts. 


Reinforcement learning. 
    - Machine can buy, sell or hold
    - How does time progress? 
    - currently agent can see the average of current candle. No ohlc data and all the previous ohlc data. 
    - Iterate over data set. 
        - Feed candle data into agent, but only the average.
        - transition to next 





Financial plan
------------------
- I need three months worth of living expenses on the side at any one time. 
- Rent 1800. Bills 400. credit card 100. 
- 




Notes testday 18-05-2022
============================
- Updading bpc file not present in v1.1. Arrow up icon missing whilst uploarding.
- Select zoom by rectangle mode in image preview, the first attempt at selection does not work
- We were able to record an image whilst the "Image output" checkbox was unchecked.
- Uploading pixel config twice?
- detector autosave.json or general autosave.json.
- Accos has been started, no detector. Writes the general autosave
- then we turn on the detector. Writes the detector autosave.josn. This works.
- However, when we then turn off the detector, only the detector autosave.josn gets updated. We also expect the general autosave to be updated. This does not currently happen.
- Then, when saving the autosave when detector is not connected anymore, accos saves the detector autosave, not general.
- When switching between detectors, the detector autosave for thw new detector is not created. Only after you change something does this file get created.
- Mainly tpx3 - consider whether we grey out record and preview buttons if bpc/dacs not loaded. Maybe Mpx3, but also reason not to.
- Version.txt system: change it so that Python will check for git, then check for existence of version.txt and if not exist create. Use `git describe --long > accos/version.txt`. Note, the "g" in output is wrong. Get rid of it. I.e. v1.0.3-74-g1fe3f74 ==> v1.0.3-74-1fe3f74
- Acos was not running, but serval was. Start up Accos but crashed.
- Frame rate is 1fps, set exposure time to S. Then type a number larger than 10. Accos tell you that the value should be less than or equal to 10. So the next thing you use, as a naive user is enter 10. Now the second error says we need to account for dead time. Better that the first error takes into account that we are not in contineous mode, then user only needs to deal with 1 error, not two.
- When detector not active, aka ready for data acquisition, consider whether we should have the stop button greyed out.
- Make writeonly error message instead a warning.


Checks
==========
- File sizes... see later.

- begining of tests: reset everything. Remove the cached ~/.config/accos (configs) and ~/.accos (logs).
- Start serval. Then start detector. Turn off detector. Turn back on. Does everyhting work okay?
- The ~/.config/accos autosave.json should be written to file, regardless of detector connection.
- When detector not connected, we need to be able to change settings in accos and the autosave.json file needs to be updated.
- Once detector is switched on, a new configuration folder is created named afeter chip board id (unique). This folder needs to have its own autosave.json configuration, specific to the detector. Each detector gets its own - hence remember settings.
- The first thing we need to do on a clean detctor is tell it where dacs/bpx files live. Or we equalize and do it ourself. Accos should popup when it cannot locate the BPC.

- Swap detectors.
- When detector is disconnected, we need to autosave it etc (as above). When we disconnect and connect to a new detector, a few things need to happen:
- If transitioning between mpx 4 chip to 16 chips, we need to make sure preview image from 512 to 1024.
- We need a new autosave.json for the new detector. The model needs to be reloaded with new settings. the UI then needs to be updated with new values.  




19/05/2022
============

- Yesterday we did some testing. Found some problems.





Slite page on pyinstaller. Use it. 

Merge permissions branch


AC- updading [pixel config twice, reset button called  twice. 




Point and figure plot
import matplotlib.pyplot as plt

BOX = 5
START = 365
changes = (8, -3, 4, -4, 12, -3, 7, -3, 5, -9, 3)

# one way to force dimensions is to set the figure size:
fig = plt.figure(figsize=(5, 10))

# another way is to control the axes dimensions
# for axes to have specific dimensions:
#                  [ x0,  y0,   w,   h]  in figure units, from 0 to 1
#ax = fig.add_axes([.15, .15, .7*.5, .7])
ax = fig.add_axes([.15, .15, .7, .7])

def sign(val):
    return val / abs(val)

pointChanges = []
for chg in changes:
    pointChanges += [sign(chg)] * abs(chg)

symbol = {-1:'o',
           1:'x'}

chgStart = START
for ichg, chg in enumerate(changes):
    x = [ichg+1] * abs(chg)
    y = [chgStart + i * BOX * sign(chg) for i in range(abs(chg))] 
    chgStart += BOX * sign(chg) * (abs(chg)-2)
    ax.scatter(x, y,
               marker=symbol[sign(chg)],
               s=175)   #<----- control size of scatter symbol

ax.set_xlim(0, len(changes)+1)
fig.savefig('pointandfigure.png')
plt.show()




20/-5/2022
============
- Yesterday I Spent time on a really simple problem. It took me more time to figure out how to test it. I learnt that in this particular instance I thinkwe need to modify the main code base to increase testability, so I stopped. Today I'll look into the problem with bpc being uploaded twice. 
- I'll spend more time getting CI set up for accos 



Reset being called, probably. 


Bore into model/Model.checkServerStatus which calls upload bpc


Testing serval
1) load accos, and serval not running. Behaves in one way. Test for this behaviour
2) load accos, serval is running. Not detector, behaves in another way. 
3) load accos, serval is runnint and detector present. 


Reset being called from loadConfigurationNotification. 
So where is the loadConfigurationNotification being posted? 
resetConfiguration posts a loadConfigurationNotification.



BPC loaded flag is not being set to True despite BPC being loaded. 
BPC has been loaded twice, we can turn off one by self.pixelConfigurationManager.reset(upload=False) inside Model.checkServerStatus()

pixelConfigurationManager.reset()

- getBPCData is None when PixelConfigurationManager is first instantiated. 
- 

first is serval.loadConfigurationNotification
second is 

BPC is being uploaded twice. 
Difficult for me to know when is the "right" time. 
one is in ServalAdaptor.putLayoutConfig via "self.model.pixelConfigurationManager.reset(upload=True)", can set upload=False
    - But actually bpc is still sent to serval twice. 

Another is in model.checkServalStatus a call to self.pixelConfigurationManager.reset(upload=True). Changing True to False and we have bpc uploaded once only. 



https://www.pythonfixing.com/2022/01/fixed-testing-pyqt-application-with.html




23/05/2022
===============
- Friday I was focused on two things:
    1) Why does the BPC get uploaded twice?
        - I was able to fix this by setting upload flag to False in putLayoutConfig. Unclear whether this was the "right" time or not. 
    2) Get the CI working on bitbucket. 
        - The tests are running, but fail with crashed python, probably because we're trying to use drivers that don't exist on the cloud. i.e. gui app. More digging needed. 

self.model.servalDetectorLayoutChanged()

IT was just a function that calls another function and nothing else. Also, other placed that could have used the function used the inner function. Inconsistent, I feel its 


BPC twice problem
------------------
- Here is the sequence of events on startup (RE the bpc):
    1) Accos starts
    2) Accos connects to the detector
    3) Accos looks for a detector specific bpc config. 
    4) If it can't find one it uses the default. 
    5) Then the layout is applied
    6) and the bpc is loaded again. 


Dirty vs clean concept. How can be make this concept OOP? Maybe we have a "TrackedVariable", which is a class wrapper around whatever it wraps. 

Is there any advantage of using a different metaclass? 

Camelian type, which appears to take on the characteristics of whatever type it holds. 


Isn't this just inheritance? Can we dynamically inherit from our input variable? 

What we want is to inherit from the class that we input in the constructor. 

Can we automatically override all methods in the class to change a "dirty" flag to True if we need to update it and False otherwise? 


@tracked
def a_method(self):
    """When called, change a flag which indicates we need to syncronize with detector/serval"""
    return "content"

Buut, we do this automatically/ dynamically. 



Who is calling mask overflow? In right click btn. action = disableOverflowPixels
- maskPixels and togglePIxels
- and alyout/ orientation 
- array bool truthy clean/dirty


Saveing and loading

Persistent BPC file, new file detector specific location. 

When starting up accos, it should check the detector specific location for a bpc file. If found use it, otherwise make a copy of the main one in the detector specific location and start using that one. 

Where is BPC loaded? 

MainWindow has a "loadConfiguration".
    - Calls Model.loadConfiguration. 
    - And then picelConfigurationManager.reset. 

    called by loadConfigurationMenu.connect. 

- We instantiate the main window and call several "triggered" methods: like `self.serverPreferencesMenu.triggered`. But these do not yet exist. How is this? 


When you click save current settings to bpc file a fn is called. We need to call this again with another argument, when appropriate. 

We need a boolean that tells us whether we need to upload or now. This in pixel config mgr. 

Thing missing is the detector specific config location
    chipboard id
    AUTOSAVE_FOLDER . join Model.getChipboardID() is specific directory

model calls loadConfiguration. inject code here. 

okay now we have the correct location


there is a                 NC.postNotification(self.LoadConfigNotification, file_)


On startup, bpc file is loaded but not autosaved immediately. 

if no detector, then it doesn't make sense to autosave the bpc

        # if not os.path.isfile(detector_specific_bpc_file):
        #     if os.path.isfile(self.BPCFileLocation):
        #         return self.BPCFileLocation
        #     else:
        #         return None
        # else:



225 EUR total 

420 for van + 200 for fuel + 310 for ticket and car 

930 / 2 = 465 each.  

300 for van + 200 for fuel + 310 for ticket and car 

810 / 405

210


How can i calculate how much money it will take to drive the price up or down by a certain amount?



24/05/2022
==========


- Start up for the first time, no detector. Global accos autosave file is generated.
- Start up for first time but with detector present, we get a pop up warning us that bpc and dacs are not yet loaded. Also get a detector specific autosave.bpc and autosave.json. These are default files. 
- Start up accos for first time. Set dacs, bias and bpc file. Then mask some pixels. Close accos. 
    - Does accos save to the currect lcoation (~/.config/accos) (bpc does, but autosave does not?)
    - Can we reload with same pixels masked? 
        - , we now have persistent bpc for specific detector. 
    - Can we delete the ~/.config/accos/bpc after loading the pixel masking. IT should return to no pixels masked. 
        - yes this is true
- We also want to only upload bpc when it gets changed. 
    - using the PixelConfigurationManager.dirty flag. 
- Does the "uploading pixel config" icon disappear properly? 
    - No the BPCLoaded flag is broken
    - The lastUploadedBPC variable is None

The save configuration in Model should also write the bpc, if needed. 

if in memory bpc different to file bpc, overwrite.  




Shouldn't reset completly reset the bpc back to the original bpc file (BPCFileLocation), not the working memory version (~/.accos/config/autosave.bpc).



this if upload should be changed to "if dirty" in PxlCfgMgr.reset.


pixelc oconfig uploading poblm us caused by the reset dirty bit. 


Dirty flag is only being set to False in ServalAdaptor.uploadBpcFileData. 

65 km + 350 - roughly 450 km * 2 ==> 900
116 miles 
100 miles 












Notes from testday 24/05/2022
==================================

Add mypy logic to CI. 
When unplugging a detector, the global autosave should be reloaded. The 


- Connect detector. Connect serval. Start accos. Verify that detector specific autosave is used. Change something. Verify that detector specific autosave has updated. unplug detector. Accos reloads with the global autosave. Change something in UI, the general autosave should be used. This worked.   


When disconnecting detector, the state of accos should reload from the global autosave state. 





Can we get a virtual display for the CI? 


xvfb-run pytest . works on server.

25/05/2022
================
- Getting CI setup for accos. 
    - I think its mostly done now, but need to get the existing tests to pass. 
- I'm playing the long game with this one. While the rigerous pre-release testing is being done manually, I'm trying to put together a test suite that can be used for Accos



jN2wrU7TYqr6zkfPDKUR





26/05/2022
===========
- loadConfigNotification being pushed.
- NC.postNotification(self.LoadConfigNotification, None) is called twice
    1) resetConfiguration
    2) loadConfiguration
        - self.loadConfiguration has a detectorSpecific flag. 
        

Improvements
----------------
- Type annotations for all methods, functions and func parameters
- CamelCase to snake case. This is Python, we should conform to python convensions. 
- We should mark private methods and attributes with prepending "_". 
- Use double quotes for doc strings, not single
- In fact, use doc strings. 
- The barrier between Model and ServalAdaptor is blurry. I'd like to separate these somehow. We should be able to use ServalAdaptor as a stand along module/package outside the context of accos. Then, any and all communication with Serval should be done through the ServalAdaptor. 
    - dashboardInfo is a Model attribute but it should actually be a Serval attribute. 



Model responsibilities
-----------------------
- I'd like to split the responsibilities of the Model, which is currently doing *a lot* of things. Via the Single responsibility principle. 
- Check server status. 









tmux commands
------------------
tmux new-session 
tmux detach





27/05/2022
============

- When detector not connected, we get lots of warnings. 


https://lcd.terra.dev/cosmos/auth/v1beta1/accounts/terra1cesylh5gtc4aherfhgh8a2554gvwlkdkkr2t73


0.3 * x = 124.768615

x = 124.768615 / 0.3  

415.895383333


Send 100 USDT to bittrue from binance


- Withdraw money from binance to kukoin, in hopes I can buy at the start of luna/usdt trading
    - Yes this is done. 
    - Now convert all usdc to USDT on kucoin. 
    - How to know when luna starts trading on kucoin????
- Arbitrage between difference exchanges. 
    - Send 80 ish dollars from binance to bittrue.  Sent, not received. 
    - Thn buy luna at the bittrue price. Send this luna to bybit and sell at this price. Then send the usdt back to bittrue
    - It is not currently possible to deposit on bybit. Which other exchanges will work? 

- You have 38 luna on kukoin
- you have 9 or so on bybit
- 6 luna on binance



Terra stuff
UTC
- Deposits and withdrawals for LUNA will open at 2022-05-31 05:30 (UTC)
- LUNA/USDT and LUNA/BUSD trading pairs at 2022-05-31 06:00 (UTC).

UK ttime
- Deposits and withdrawals for LUNA will open at 2022-05-31 04:30 (GMT)
- LUNA/USDT and LUNA/BUSD trading pairs at 2022-05-31 05:00 (GMT).

My plan 
    - transfer all my luna to binance at 5am on Tuesday 31st. 
    - Use 1000 BUSD or USDT. Maybe USDT since its bigger. 
    - On market opening time, place a market buy order when open. The price will shoot up and then down again very quickly. 


Crypto average data
- Download all daily data sets, store locally. 
- Normalize the data to 0 and 1 so that price doesn't factor into it. 
- simpl averaging. 
- clustering. 


We need a way to filter the symbols based on when they were first listed on binance. 










30/05/2022
==========
- When serval is not connected to emulator, do not try to reload configuration files. 
- BPC/DACS are only uploaded once. 



Improvements
================
- The barrier between Model and ServalAdaptor is blurry. I'd like to separate these. We should be able to use ServalAdaptor as a stand along module/package outside the context of accos. Then, any and all communication with Serval should be done through the ServalAdaptor. 
    - dashboardInfo is a Model attribute but it should actually be a Serval attribute.
- When model.postUpdateUI is called it calls functions that listen to the ModelStateChangeNotification. In some cases, like uploading DACs, this mechanism has been abused. This is because we call postUpdateUI often and we rarely need to update the dacs. Currently we mitigate the effects with conditionals inside the serval function that handles uploading dacs. Indeed, this mecahnism includes an akward copy of the DACs called lastUploadedDacs which is used to only update DACs when they have changed. 

I think we should 
    1) create a DACsStateUpdatedNotifiation instead and only upload dacs when needed. This then, impacts BaseModel.setMV since if a DACs related metadata is updated we need to push a DACsStateUpdatedNotification rather than postUpdateUI(). 
    2) turn DACs into an object in its own right, which makes distinguishing and comparing DACs easier. (chipcheckers library already has an implementation for this).

- postNotification currently requires interface with arguments that are not always needed. This can be mitigated using *args and **kwargs. 


Small things
---------------
- Use doc strings on all methods. These are for us, not customers. 
- We should mark private methods and attributes with prepending "_". 
- Type annotations for all methods, functions and func parameters
- name of the project should be "Accos" not "guiapp" 
- Use double quotes for doc strings, not single
- CamelCase to snake case. This is Python, we should conform to python convensions.
- 


Model responsibilities
-----------------------
- I'd like to split the responsibilities of the Model, which is currently doing *a lot* of things. Via the Single responsibility principle. 
- Check server status. 


- I started a new branch. Now dacs are being uploaded multiple times. 
- ServalAdaptor.modelStateChanged is called when the ModelStateChangedNotificiation is pushed. 
- ModelStateChangedNotification is a global push that affects everything. 
- Maybe we could change this to DACsStateChangedNotification. 
- We have the DACsStateChangedNotification, where do we actually need to push DACsChanged? 
- Look at places which push the DACsStateChangedNotification. 
    - One in the BaseModel in postUpdateUI
    - So we need to search for uses of NC.pushNotification with DACsStateChangedNotification and of postUpdateUI. 



31/05/2022
=============
- Fixed DACs that were being uploaded many times. 
    - I created a DACsStateChangedNotification to do so because the ModelStateChangedNotification is so overloaded, that we attempt to upload the dacs often. This was is more targeted. 
- Besides this I spent time looking into how to properly test QT application. 
    - I know how to test QWidgets in isolation 
    - However I am yet to get the full UI working in a test environment. The problem is that once you enter the main loop, you are already outside the main loop. 


- remove the "dirty / clean mechanism for BPC uplaoding. Instead use another notification. BPCStateChangedNotification. 

- Does any of the up elements get updated when DACs are changed? 

- DACsFileLocation is empty string, yet we still try to upload it. 


DACs are being uploaded, even when the DACSFileLocation is empty string. This is okay, they are default settings. 

Say in log that when we are uploading the default DACs/BPC. Distinguish this from other times. 

Okay, how to start from the begining? 

- ServalAdaptor.uploadBpcFileData to Serval. It uses PixelConfigurationManager.getBPCData() methods for collecting the data. 
- PixelConfigurationManager has an uploadBPC() method which uses ServalAdapter.uploadBpcFileData.
    - ServalAdapter.uploadBpcFileData is called by model.acquireCalibrationData and  by PixelConfigurationManager.uploadBPC.
    - PixelConfigurationManager.uploadBPC on the otherhand is called in several places in the PixelConfigurationManager and by the EquilizationWindow.revertEQModelSettings. 
- ServalAdaptor is the lower level API and it should (and is) just used by the rest of accos. 

- I have changed model.acquireCalibrationData so that it uses the PixelConfigurationManager.uploadBPC.
- Now, any time the BPC has changed and needs uploading we push the BPCChangedNotificaiton. Who needs to listen to this? 
    - Well who currently calls PXL.uploadBPC? 
        - EqualizationWindow
        - Model.acquireCalibrationData
        - PixelConfManager in multiple places. 
- Where do we set dirty to true? 
- The dirty mechanism ensures that we do not upload pixel config until we are ready. This allows us to make multiple changes before uploading. Can the same thing be done with notifications? 

- remove dirty. remove notificaiton. Replace the bool if statement. 


Testing plan
- Which methods call uploadBPC?
    - togglePixelMask
    - maskPixels
    - reset
    - readBPC




- Can I overload the setattr in PixelConfigurationManager to set the dirty flag if something has changed. 

- Is there any difference between what I have done and what was there before? 
- It occure to me that this dirty/clean system always will always get trigggered when anything is changed. 

    - Or we need to set dirty to True once the BPCFileName is changed? 
    - Also, we already have a BPCLoaded vairable which essentially does the same thing as dirty!

- Tuesday in the office. 
    - Benamino
    - Jasper 
    - Jord
    - Fei
- Send to these guys before we 
    - Brum
    - Rick
    - 

- Write a page synopsis on what we are looking for. 


Things to do
--------------
- Write a synopsis for what is needed with regards to testing. Send to the above llist of people. First Bram and Rick. 
- Finish up the PixelConfigurationManager setattr code. 
- Learn about the scalping strategy from youtube




put layout is the first to try to upload bpc.

Who pushed modelStateChanged? This is a notification, it has a sender, the notification and set of listeners. How can I trace who sent the notification?


I think accos is "over connected". That is, the notification system calls lots of things, often even when they do not need to be called. It would be better to have more types of notification that act in a more targeted way. 


So any time model.dacs or model.DACsFilename is assigned, the DACSStateChangedNotificaiton is pushed. 
loadConfigNotification does this. 


           #   todo: discussion
            #    When model.postUpdateUI is called it calls functions that listen to the
            #    ModelStateChangeNotification. In some cases, like uploading DACs, this mechanism
            #    is overloaded. This is because we call postUpdateUI often and we rarely need to
            #    update the dacs. Currently we mitigate the effects with conditionals inside the
            #    serval function that handles uploading dacs. Indeed, this mecahnism includes an
            #    akward copy of the DACs called lastUploadedDacs which is used to only update DACs
            #    when they have changed.
            #    I think we should
            #        1) create a DACsStateUpdatedNotifiation instead and only upload dacs when needed.
            #        This then, impacts BaseModel.setMV since if a DACs related metadata is updated we
            #        need to push a DACsStateUpdatedNotification rather than postUpdateUI().
            #        2) turn DACs into an object in its own right, which makes distinguishing and
            #        comparing DACs easier. (chipcheckers library already has an implementation
            #        for this).
            #       -- Ciaran
            # if key in ["DACSFileLocation", "dacs"]:
                # todo this mechanism isn't ideal and is a small patch put in place until
                #  a better solution can be implemented (see above).
                # NC.postNotification(self.DACsStateChangedNotification, None)
            # else:
677580


Accos has been started, no detector. Writes the general autosave 

then we turn on the detector. Make a change. Tehn we write to the detector autosave.josn. This works. 

However, when we then turn off the detector, only the detector autosave.josn gets updated. We also expect the general autosave to be updated. This does not currently happen. 

When we turn off the detector, the settings inside the detector autosave should be copied to the global autosave. 

Then, when saving the autosave when detector is not connected anymore, accos saves the detector autosave, not general. 

When switching between detectors, the detector autosave for thw new detector is not created. Only after you change something does this file get created.

How can I detect when we go from connected to detector, to nor detected. 

Even when detctor and server are conected, does the checkServerStatus function get called 3 times a second. Might be able to provide a callback in the repeated timer
            
01/06/2022
===============

Scrum
-----
- working on dacs and bpc uploading. 
    - DACs has its own notification, but I'm not sure of the impact since notifications can trigger notifications
    - build a little option for inspecting the notification system. 
    - The dacs-uploaded-twice branch 
- timepix3 submodule has the tpx3_analysis folder back again. We renamed this because the symlink solution is not cross platform. 
- new errors in accos v1.1:
    - Send systemConfig Error ...
    - Is this because we need a new version of serval ? 

- Contribute towards the testing. Options:
    1) Remotely hook my into the lab computer and I participate as if I were there. 
    2) When you find issues, send them to me and I'll try to fix them here. 
    3) Too difficult, I continue to work on accos issues. 

- review the PR's 
- mypy to ci. isn't as impolrtant. 


When you kill emulator/detector whilst running preview, serval keeps taking the measurement. 





Customer noticed a small bug in the software: when using
the log display the software crash if we shut the beam before stopping
the preview (or record) mode. This is most probably because the 0
intensity case is not secured (log(0)= not good).

 

What to fix:

In PreviewVC.py it could happen that when the log mode is on, an zero in the input preview image leads to a log(0) situation in the code below:

 if self.model.previewLog:
            # Remove the zeros before calculating the log.
            # Also if the lower level is zero take the minimum
            # non-zero value instead, since the log of 0 is -inf.
            data = np.copy(data)
            nonzero = data != 0
            
            if self.model.imageMode == 'count':
                min_ = 1
            else:
                min_ = np.min(data[nonzero])
             
            data[~nonzero] = min_
            data = np.log10(data)
  




tmux commands
===============
tmux new-session
tmux list-session
tmux kill-session
tmux detach





01/06/2022
===========



RSI
---
- Relative strength index is a momentum indicator. It measures the rate of increase by computing the proportion of up bars to down bars. When RSI > 50 it the price is increasing. When RSI >> 50, the price is moving upwards faster. Same is true for bearish trends. 
- RSI divergence is where the price forms higher highs while the RSI forms lower lows. 


Regular Bullish Divergence 
---------------------------
- If the price is making lower lows but the oscillator is making higher low, this is considered a regular bullish divergence. 
- This usually happens at the end of a bear trend

- Find some on the cardano chart



- I'm looking for a divergence between what the price and the RSI are doing. 
- Currently trading above the 200 smma so looking for a bullish position


- Start on the higher time frames, mark up the chart on the higher time frames
- 

RSI is going up but the price action is going down - you have a divergence. 





Start by identifying lows and highs


How to identify the current trend? 
------------------------------------
Two things: 
    1) Using the RSI. If you are above the 50 line and moving, you are in an up trend. 
    2) If the 200 moving average is slanted upwards, or downwards, this indicates trend. 
If both of these are present, we are in a trend. 



02/06/2022
--------------
- I was working on issues. 


todo
------
- Review all open PRs
- Write the synopsis for jord
- work more on an issue. 
- Book car rental with johannes
- Talk to lilly, figure out her shit as well. 
- trading, trading, trading. 






- can we dynamically change the AccosMetadata values? 
if condition AccosMetadata[imageFormat].allowedValues = ["tiff"]







When model.postUpdateUI is called it calls functions that listen to the
ModelStateChangeNotification. In some cases, like uploading DACs, this mechanism
is overloaded. This is because we call postUpdateUI often and we rarely need to
update the dacs. Currently we mitigate the effects with conditionals inside the
serval function that handles uploading dacs. Indeed, this mecahnism includes an
akward copy of the DACs called lastUploadedDacs which is used to only update DACs
when they have changed.
I think we should
  1) create a DACsStateUpdatedNotifiation instead and only upload dacs when needed.
  This then, impacts BaseModel.setMV since if a DACs related metadata is updated we
  need to push a DACsStateUpdatedNotification rather than postUpdateUI().
  2) turn DACs into an object in its own right, which makes distinguishing and
  comparing DACs easier. (chipcheckers library already has an implementation
  for this).
     -- Ciaran



Synopsis for testing
=====================
Testing new code in ASI software is currently an inefficient process. We do not have standardized test devices and not all of our software has automted testing. This is something we hope to improve on in coming weeks/months. 

Specifically we would like a dedicated computer and device for each type of device that we have. We will set this up so that software dev's can hook into this system and develop against real devices, regardless of whether they are in the office or not. Importantly, these devices will have been properly tested manually and maintained. Since these devices represent the baseline working model, if they are broken we will write broken code. 

Eventually I will try to hook our software test suites up to our contineous integration platforms so that every time one pushes new code to bitbucket servers, bitbucket servers will push back to the lab computer which will run all of our test on all of our devices. This will significatly enhance the software development process at ASI but will also facilitate the hardware development process, since we'll be able to hook an experimental detector into software with known behaviour. 

Hopefully you agree that this is worth doing. Look forward to discussing this with you all, 

Best, 
Ciaran 


https://lcd.terra.dev/cosmos/auth/v1beta1/accounts/terra111111111111111111111111111111111111111








sudo dpkg --add-architecture i386
sudo apt-get update
sudo apt-get install gcc-multilib
sudo apt-get install zlib1g:i386



03/06/2022
===============

Scrum
------
- Reviewed/Merged some PRs
- Wrote rational for testing equipment. 
- Write some issues for accos. 
- Spent the afternoon helping Siamack out
- Started an accos issue but didn't get very far with it. 





How to risk 1%?
Available = 3,246.47 usd. 
1% = 4 usd. 
if I put 50


- When in 24 bit mode, the other pixel depths get greyed out. This mechanism can be reused. 

- if MedipixSettingsWindow.threasoldWidget == "CSM - 1 x 24 bit - shutter based":
    - do this "        self.pixelDepthWidget.inputWidget.model().item(0).setEnabled(not csm) # 1 bit" 








ValidatedWidget is an abstract class. 
It cannot be used instantiated directly, since it is missing the inputWidget. 
- Make it abstract. 

Separate the validation function from the widget/layout function. 


First fix this issue. No faffing. Then start new branch and start implementing this idea. 


@startuml


' this is what we have
'abstract class ValidatedWidget
'
'class ValidatedIntWidget
'class ValidatedChoiceWidget
'class ValidatedStrWidget
'class ValidatedBoolWidget
'class ValidatedFloatWidget
'class ValidatedColorWidget
'class ValidatedFileWidget
'class ValidatedDirectorySelectorWidget
'class ValidatedFilesWidget
'
'
'
'ValidatedWidget <|-- ValidatedIntWidget
'ValidatedWidget <|-- ValidatedChoiceWidget
'ValidatedWidget <|-- ValidatedStrWidget
'ValidatedWidget <|-- ValidatedBoolWidget
'ValidatedWidget <|-- ValidatedFloatWidget
'ValidatedWidget <|-- ValidatedColorWidget
'ValidatedWidget <|-- ValidatedFileWidget
'ValidatedWidget <|-- ValidatedDirectorySelectorWidget
'ValidatedWidget <|-- ValidatedFilesWidget


abstract class ValidatedWidget {
    {abstract} getInputWidget(): QWidget
}


class ValidatedIntWidget{
    + getInputWidget(): QSpinBox
}

class ValidatedChoiceWidget{
    + getInputWidget(): QComboBox
}

class ValidatedStrWidget{
    + getInputWidget(): QLineEdit
}

class ValidatedBoolWidget{
    + getInputWidget(): QCheckBox
}

class ValidatedFloatWidget{
    + getInputWidget(): TrimmedDoubleSpinBox
}


ValidatedWidget <|-- ValidatedIntWidget
ValidatedWidget <|-- ValidatedChoiceWidget
ValidatedWidget <|-- ValidatedStrWidget
ValidatedWidget <|-- ValidatedBoolWidget
ValidatedWidget <|-- ValidatedFloatWidget







@enduml



When you change from different mode to 24bit, we need to change the file type. 


New class called `Options`. This is the base type for all model options. We then have model.LeftPaneOptions() for example. Then, LeftPane only communicates with LeftPaneOptions. 





Hierachucal notifications. Top level Notifications call all child notifications but child notifications do not call parent notifications. 






Override __new__ and __call__ for validating data. 



Hey Erik - good to e-meet you! I've been friends with your bro for a long time and he mentioned your company is recruiting. I've recently moved into a physics based software engineering role but for many reasons its not quite cutting it. Would be great to have a conversation with you and company about what I could potentially bring to the team. I have a couple of minor changes to make on the CV Will sent you.


The Moving Avergage
======================
https://www.youtube.com/watch?v=LW5WGbzCPAE

You watched about 4min of this video. Keep going. 

- Each time you lose a trade, write down what happened. This can help learn from it. 

Mark up chart
--------------
- First thing you do is draw up support and resistence levels
    - These are usually even numbers! Psychologically they just are for some weird reason. 
- Mark up the chart on higher time frame - daily. 

Get overview
-------------
- Before looking at any indicators, just look at the chart. 
    - Try looking only at one pair, until you've mastered it, do not go onto another. 
- Look at the direction of the price. Is it an uptrend, downtrend, sideways? 
    - Within a trend, you have market structure. The price will go down and up within the up or downtrend. 
    - For instance, if downtrend, you'll get a lower high and a lower low. When this market structure is broken, you'll price reversal. If uptrend, you get a low high, but fail to get a higher high, the trend is broken. 
- When you have strong momentum in a direction and have a kick back in the other direction before continuing the trend. This is called a retracement. 
- You can use a fibonacci retracement tool to look at what percentage of price movement the retracement retraced. 



Would be cool to try testing lost of strategies. Optimization. 
Let the RL agent pick from features. backtest. Score. Optimize the score. 



07/06/2022
============


- When FPS is changed to >500, check to see if the Preview.showIntegrated button is checked. 
    - When yes, warn user about high frame rates + integrated preview. 
    - When no, leave it. 
- Also, the showIntegrated checkbox could be checked after the frame rate. 
- Have a static PreviewManager method to deal with the logic. Use it in multiple places. 

        """When the integationEnabled checkbox is checked and frame rate is above
        500 fps, there is an increased risk of dropping frames. Warn users of this.
        
        This method needs to be called in two situations: 
            1) When fps is changed to >500fps *and* the integrationEnabled checkbox is True
            2) When the integrationEnabled checkbox is True and when the fps is already above 500 fps. 
        """


        warnIntegratedEnabledAndHighFrameRate


Validation functions should all implement an interface. They should be classes with an overloaded __call__ operator








class FrameRateValidation(ValidationFn):
    """Validates the frame rate input

    todo see issue AC-123: ValidationFn types should have thier own class hierarchy

    """

    def __init__(self, frameRate, exposureTime, model):
        self._frameRate = frameRate
        self._exposureTime = exposureTime
        self._model = model

    def __call__(self) -> bool:
        self.validateDeadTime()
        PreviewManager.warnIntegratedEnabledAndHighFrameRate(self._frameRate)

    def validateDeadTime(self):
        assert(self._frameRate != 0)

        # When frameRate = 1.0 and exposureTime = 0.9995, 1/frameRate - exposureTime evaluates to 0.0004999999999999449, while
        # it should pass validation. As workaround we round it.roundedDeadtime = round(1/frameRate - exposureTime, 8)
        roundedDeadtime = round(1/self._frameRate - self._exposureTime, 10)
        mdt = self._model.deadTime()
        if roundedDeadtime < mdt:
            maxF = 1/(mdt + self._exposureTime)
            maxF = math.floor(maxF)

            msg = "Frame rate is too high for exposure time"
            if maxF > 0.0:
                maxF = np.format_float_positional(maxF, precision=4, unique=False, fractional=False, trim='-')
                msg += "\nMax: " + str(maxF) + " fps"
            msg += " Dead time: " + engineeringFormat(mdt, 's')
            return (msg, float(maxF))
        else:
            return (None, self._frameRate)
        print("frameRateValidatoinFn valled. ")

from accos.model.PreviewManager import PreviewManager
if self.model.frameRate >= 500 and self.model.integrationEnabled:
    PreviewManager.warnIntegratedEnabledAndHighFrameRate()







Small tasks that make a sucessful day trader: 
    - make a demo account. 
    - make 3/4 demo trades every day for 6 months, record them all, incl. screenshot of the analysis on trading view. 


Make a list of my goals in life. 
Make a sublist of tasks for each goal. 
Start working through the sub goals. 

- Learn to play guitar
- Be a sucessful trader in forex/crypto/stocks. 
    - Do 3/4 paper trades per day. 
- Get stronger and fitter. 
- Write a crypto dapp
    - Crypto poker game. 
    - Use Golang or rust
    - Maybe even jsut c++? 
- How to get better memory?




"""When the integationEnabled checkbox is checked and frame rate is above
500 fps, there is an increased risk of dropping frames. Warn users of this.

This method needs to be called in two situations: 
    1) When fps is changed to >500fps *and* the integrationEnabled checkbox is True
    2) When the integrationEnabled checkbox is True and when the fps is already above 500 fps. 
"""

- In LeftPane the integrationEnabled validation widget uses the setEnabledFn. 
    - What is this setEnabledFn? Callback mechanism like ValidationFn? 
- Enabled is greyed out or not, NOT the value of the checkbox!. 
- Maybe I need to look at the validation mechanism itself? 
- Now need to look at how to add a validation mechanism to the MD. Do this by finding an example of how it is done. 


How to get status bar to post warning. Or is it just errors for status bar? 

08/06/2022
==========
- Started a issue - warning when integration is on and high frame rate. 
    - Same warning multiple places? This warning affects two different widgets. 


- Looked at the build system for spidr project. 
- Looks like there are a few problems with the compilers due to bitness. 
- I thought I had the compilers working on my system - there was a problem with bitness. Thought I'd resolved this issue but actually there still seems to be a problem with bitness. 

My recommendation:
- Rebuild the compilers but on a 64 bit machine with the relevant compiler flags. 
- Package this into a docker image so that the build enviornment is always accessible. 
- Alternatively, though not sure how viable, you could use the newer compilers. Is there any advantage of upgrading your code to use the newer compilers? 

- Found a mutual dependency between two of the projects. Not sure exactly how to resolve this but will look closer today. 

bias voltage not enabled. Use this for warning. 
    Leon. 


Sorry about that Maurits. In short, I worked on an issue this morning and decided to put more effort into the test suite this afternoon. 


Accos
compile on 18, move to 20 see what happend


Trading goals
---------------
- Learn about the formations and candle stick patterns.
    - Pick a pair, look for 5 - 10 examples of each pattern. Screen shot them and record them. 


Trading Questions 
-------------
- How important are the wick sizes in recognizing candlestick patterns? For instance, if you thought you saw a bullish hammer but the middle green wick is short instead of long, does this invalidate the hammer pattern? 
- Formations are commonly observed patterns which give an indication of the future price movement. Are there also times whereby a significant price movement is observed but it does not fit into any kind of formation? How common are these situations? 


09/06/2022
==============

Scrum
------
- We wanted a warning on the status bar when high frame rate and preview integrated image is on. 
    - I decided not to do this on the existing warning "light" (third green circle in on the status bar) because I wasn't sure what would happen when more than one warning is present. 
    - Instead I Implemented a way to post warnings to the status bar, much in the same way as we have an error.
    - Implementation wise, we could probably make this more general. Currently Its basically duplicated code, which I'm feeling a little guilty about, so I'm thinking I'll clean this up today. 

- Going to start working on PyInstaller integration into the CI. 


- Get link from trading firm


- Why does the validation step happen when ModelStateChangedNotification

LeftPane.timerFires calls pushes a ClearStatusBarErrorNotification

ValidatedDirectorySelectorWidget.validate gets called when you open SensorSettings window


So, opening SensorSettings causes a ValidatedBoolWidget to call ValidatedWidget.updateUI with a ModelStateChangedNotification. UpdateUI calls the validate function, like it should. 

The validatedBoolWidget must be the integrationEnabled checkbox. How can I veriufy this? It must be true, because its only called in one place. 

Maybe wires are getting crossed between sending errors or sending warnings to status bar? 







import pytest
import pytestqt
from pytestqt import qtbot

from accos.view.StatusBar import StatusBar
from accos.view.MainWindow import MainWindow
from accos.model.Model import Model
from accos.config import ACCOS_DIRECTORY


def test(qtbot):
    model = Model(ACCOS_DIRECTORY)
    main_window = MainWindow(model)
    status_bar = StatusBar(model, main_window)

    print(status_bar)







SensorSettingsWindow calls a postUpdateUI. 

So whenever biasEnabled is toggled, the postUpdateUI method is called. 

When sensory window opened it is also called. 

So, why does the postUpdateUI (aka push ModelStateChangedNotification)method call the integrationEnabledValidationFn?

LeftPane.updateUINotification listens to ModelStateChangedNotification.

The validatedWidget observed the model state changed notifications. So whenever a model state changes, all widgets get revaldidated?

After frameRate widget submits, I want to run the validation function. 



Put time in with gf
    - block in some time for her

Exercise
    - Be able to run 21Km

Trading
    - Get setup with a broker. 
    - Open a demo account
    - place a long
    - place a short
    - Find historical examples of different types of structure/formations
        - Names of formations? 
    - Learn RSI divergences by heart. Bull/bear hidden vs not hidden
    - What is the *** wave (what was the name?)
    - Learn and find examples of candlestick patterns
    - grow a demo account 10x . 

Algorithms and data structures
    - Linked lists
        - create
        - insert
        - merge
    - Binary tree's
        - Create
        - use for searching
    - Priority Queue
    - Queue
    - Hash maps
    - two pointer algorithms
    - prefix sums

Photography
    - Make good use of

Guitar
    - Start learning songs

Work
    - Do work really fast so that I have something to say that I did and move on to learning what I really want to learn. 


No alcohol
No coffee
No meat 





My problem with this algorithm training I'm doing is that I'm trying to *solve* everything by myself. Instead, I should be learning the algorithms made by other people. 

Funily enough, when I can't solve a problem after spending hours on it I get mad at myself and depressed, and think I'm shit at programming. But it is unrealistic to expect myself to be able to work out all of these algorithms by myself. 


10/06/2022
===========
- Build breaks into my work. 
- "Modified the StatusBar so that other types of notification can be pushed to the status bar. However still have a problem using this mechanism via Validation mechanism because the warning then gets push whenever ModelStateChangedNotification is pushed."
- Managed to get the PyInstaller to work, with a few changes to the script.


- I can get PyInstaller to work locally. 
- Had to make some changes to the script 
Next -->
- Need to include the test files into the dist
- Need to add a option under one of the menu's for running the tests. 
- Then build dist on the CI
- Install the debian file
- Needs to be tested on a machine without python. 
    - Is it possible to use a second pipeline for testing accos build on another clean docker image. 
- then run the tests (or subset) to make sure its working. 
- inhibit in-source builds. 



trading
=======
- Always buy from a support
- A support is a support because there are lot of people wanting to buy at the support. For this reason, it is also known as a liquidity pool.
- The same is true for resistance, but for sellers. 
- always sell from a resistance
- after a break in support or resistence, you should wait for the "retest" before placing a trade. 


13/06/2022
============
- Made progress with pyinstaller build script. 





if the minimum trading volume on AUDUSD is 0.01 lots, which is 1000 AUD and we want 1% risk, does that mean we need 100,000 at least before we can start trading. 

Hi Guys, I'm fairly new at forex trading and still trying to work some things out. This *might be hard to answer but I'm confused so will ask anyway. I have $20 in an ospreyfx account and put a short position on AUD/USD for 0.01 lots. My stop loss was 15.2 pips and risk/reward ratio was 3.37. The journal excel spreadsheep provided by TTF suggests that the result of this trade should be $0.67 but my actual gain according to ospreyfx was $4.75. My question is why the discrepency? Thanks.


15/06/2022
===========
- Yesterday I worked on fixing chip ID numberings 
- I also rebuilt the test PC, which is ready to go. 
- 


PreviewVC.rangeChanged might be a better place for updating ratio. 

was in updateUI method. Move to RangeChange method and see if it works
make sure the ratio is being updated? 

Good, progress. But we now need to get the visible portion of the axis size only. 


Add two more decimals for hardware status. 
Add additional chipBoardID ChipboardTemperatures




Sardinia
-----------
- mosqito cream/net/healer???
- sleeping bag
- torch and charger
- camera
- tent
- blow up mattress
- sandles
- pump 
- make sure credit card works
- book travel for airport on other end
- portable charger
- phone charger
- shorts
- hair cut


wait for the 15 minute to hit the bottom before going long.






17/06/2022
===============
- Made a few PR's, I'll spend time looking at comments and hopefully get these merged
- Maybe 

I will check that builds are portable between ubuntu 18 and 20













install autotools 
sudo apt-get install -y gperf gettext libtool autopoint autotools pkg-config libfreetype6-dev ibexpat1-dev

install freetype 
    freetype2-demos

remove existing fontconfig
    sudo apt remove fontconfig

Need to install GL libraries on 20. 
    apt-get intall -y mesa-utils and libgl1-mesa-glx


how to minimuze size of pyinstaller




17/06/2022
---------------
- Build on ubuntu works, but not portably so. 
- I have been unable to resolve the font problem
    - Tried compiling the package from source with a newer version before using pyinstaller. 
- Since I can't find a way to fix this problem, I thought it a good idea to build a docker container for both 18 and 20 so that we can build on both in the CI. This is in progress. 
    - I'm removing conda from the CI container and instead using plain python. Its more work, but the executables will be smaller. 
    


- So, plan of attack?   
    - Build the docker images
    - 


- Buy bitcoin at 16000 to 16250
- Buy eth at 700-800




04-07-2022
============
Problem with glibc version between ubuntu versions. 
thge packaged python version uses the system libm.so which is looking for C version GLIB_C2.29. Which version exists? We have GLIBC2.27 (`ldd --version`). 


Can we use manylinux? 

If we were going through the regular pip way of distributing this code, it would work. 

Since we use Qt and Qt is C++, we may need to build on manylinux. 
I could test this by compiling a simple hello world vs hello qt script in each env. 

Do so. 

1) build hello world with ubuntu 18 env. Does it work on ubuntu 20.04? 
2) build hello world with ubuntu 20 env. Deos it work on ubuntu 18.04?
3) build hello qt with ubuntu 18. Does it work on 20.04? 
3) build hello qt with ubuntu 20. Does it work on 18.04? 


Currently I have two leads
    1) Running pyinstaller with the docker image on a basic hello world provides a warning that if you built python yourself you should consider using the --enable-shared option. 
        - Secondary problem: I did not set the LD_LIBRARY_PATH. Trying to fix this in the right way. But maybe it is better to fix the quick way just to see if it works. 
        - The right way is the rpath when ./configure. 
        - quick way is to export the right path when using python. Every time. 
        - set rpath to home or orign
    2) When building the accos executable there is warnings about missing shared libraries. We can add these with the --add-binary flag, or probably equiv in the spec file. 
    3) build using manylinux.


ubuntu 18.04 to 20.04 still has the font issue. 


backwards compatibility works, but not forwards compatability. 

Ubuntu 18.04 uses gcc 7.5 by default. GLIBC 2.27. 
Ubuntu 20.04 uses gcc 9.4 by default. GLIBC 2.31

When installing gcc 9 with :
```
RUN add-apt-repository -y ppa:ubuntu-toolchain-r/test
RUN apt update
RUN apt install -y gcc-9
```
which version do we get? 9.4 and glibc 2.31. So we try to build on 20.04 and use it on gcc 7.5. 

try to include libm in the build? 


Currently trying to add the shared libraries responsible for the errors to the build environment. This takes a lot of time, but will follow try more tomorrow. 
    libm
    libc
    pthread 
    

05-07-2022
==============
- I want 2020 to be our main version but for this to also work on ubuntu 18.04. 
- I've tried a bunch of things but still not got it right yet. 
- I'm starting to suspect that it might be better/cleaner to

- Yesterday I fixed some problems but caused others. 
- Its fairly complicated, so I'm putting my thoughts in writing. 


- Could try manylinux? 

- Currently trying to add 

The problem is that native versions of C are different between Ubuntu20.04 and 18.04. There should be some degree of backwards compatability but the shared libraries used in the build environment are different versions than that of the run environment. This causes strange behaviour. Usually, in the C/C++ world, binaries are built from source on the system being used - that is, either a precompiled version for each system or provide the sources for users to build themselves. We cannot do the latter, but we can do the former and I suspect this might be our best option for now. 

Another option is to try the build in a manylinux environment. When building pip wheels with binaries on linux, you must use a "manylinux" system - which is a centos environment. They do this because Centos is the common denominator for most modern linux systems: binaries built on Centos have the most chance of suceeding. We could try this also. 

Another option is to include the offending libraries in the distribution ourselves. That means when migrating from 20.04 to (say) 18.04, we do not use the native libraries but the ones we provide ourselves. We can do this in two ways, firstly we could manually figure out which libraries we need (libc.so.6, libm.so, pthread.so and more). Or we could make sure that every computer that uses accos has correctly installed the right C environment. The former is prone to errors, increases binary sizes and might not even be feasible - I do not know, since I do not know how many libraries we'll need to include. The latter means that we need to either install C environment on our customer PC's or get them to. Whilst an unattractive option it does provide a degree of future proof since we'd be able to go straight to a modern version of C/C++.  

It should be noted that we are having this issue mainly because we are using PyInstaller to build an executble. Our sources are basically just Python and data/jar files (Qt is C++ but handles this problem itself using the traditional pip wheel mechanism). The traditional mechanism does not work for us because we need to hide our sources from the customer. However it *might be possible to compile our sources into pyc files and then use the traditional mechanism for distributing accos. Pyc files are compiled Python sources, though apparently relatively easy to decompile. 

It would have to be a private channel.

Other things to do today
------------------------
- fix the hack to get packaging only to work on master branch
- Start writing tests. 




Couple of reasons
--------------------
- I thought I'd be able to do it remotely
- I need to work on my laptop today so thought it was easier to stay home. 
- 


Payment reference for UTR self assessment tax July
4557645397K


# There is a bug in numba, a dependency used by
# the tpx3_converter package, whereby when used with pytest on windows,
# numba crashes Python (see https://github.com/numba/numba/issues/8223)
# Only importing tpx3_converter
from accos.feature_config import HDF5_CONVERTER
if HDF5_CONVERTER:
    import tpx3_converter as TA  # Timepix Analysis



<leave space for merge conflict>































07-07-2022
==============

Scrum
-----
- The pyinstaller PR is ready for review
    - Its working. Do you want to review it, or should I merge it? 




- Other than that, I've been working on cleaning up test suite and developing more tests. 
    - currently producing some tools that standardize the test starting conditions. Starting and stopping accos. 
        - Before every test, we must load dacs/bpc
        - After every test, we must clean up autosave

I've made a good start but it'll take me longer to get it right. 


- Had a conversation with Fei. We will get one computer and one detector initially for configuring the test systems. 
- Pui showed me to a computer that we can use but when I asked him about wiping it he seemed suprised and unsure so now I don't know whether we can still use this machine. I messaged him on teams but no response yet. 
- I do not know what happened to the computer that I build before my holiday, it has disappeared. 




- Tests need time to wait for serval to start. We need a Qt Signal to mark this event so that we can wait for it. 

08-07-2022
===========

Scrum
------
- Problem: The first thing accos does when you start it up using a fresh detector (no autosaves etc) is send the user a warning about missing dacs/bpc. I'm currently trying to work out how to handle this during tests. 



Things to do
--------------
- Strategy on tradingview
- clean apartment
- binary search
- bike shopping
- forex





11-07-2022
=============


Scrum
-----
- The problem I was solving last week: 
    - The first thing accos does when you start it up using a fresh detector (no autosaves etc) is send the user a warning about missing dacs/bpc. I'm currently trying to work out how to handle this during tests. 
- I figured out that it is possible to get around this by mocking the QMessageBox.exec function. 
- I moved some code around a little regarding the warnings for improved testibility. 
- I've also located the instructions for self hosted runners. I will need admin access to set this up. 

video instructions
    - https://www.youtube.com/watch?v=ditUFbBZpts
Documentation for self hosted runners
    - https://support.atlassian.com/bitbucket-cloud/docs/runners/
    - https://bitbucket.org/blog/pipelines-runners






Okay so lots happened today. 



- Self hosted agents are up and running. The process needs to be streamlined a little. 
    - It should be possible to have multiple instances of the required docker container running so that we get parallel builds 
    - It should also be possible to stop the container and then start it again, though for some reason this breaks. 
- The pipeline runs, but it is broken when hosted locally because Python installation is different location. I can fix this easily.  



So, it seems I am able to use the nested docker container correctly, but we cannot clone the repository due to permissions. 

July BF I accidently changed. 


Scrum 









